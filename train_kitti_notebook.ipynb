{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "from faster_rcnn import network\n",
    "from faster_rcnn.faster_rcnn import FasterRCNN, RPN\n",
    "from faster_rcnn.utils.timer import Timer\n",
    "\n",
    "import faster_rcnn.roi_data_layer.roidb as rdl_roidb\n",
    "from faster_rcnn.roi_data_layer.layer import RoIDataLayer\n",
    "from faster_rcnn.datasets.factory import get_imdb\n",
    "from faster_rcnn.fast_rcnn.config import cfg, cfg_from_file\n",
    "\n",
    "try:\n",
    "    from termcolor import cprint\n",
    "except ImportError:\n",
    "    cprint = None\n",
    "\n",
    "try:\n",
    "    from pycrayon import CrayonClient\n",
    "except ImportError:\n",
    "    CrayonClient = None\n",
    "\n",
    "\n",
    "def log_print(text, color=None, on_color=None, attrs=None):\n",
    "    if cprint is not None:\n",
    "        cprint(text, color=color, on_color=on_color, attrs=attrs)\n",
    "    else:\n",
    "        print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyper-parameters\n",
    "# ------------\n",
    "#imdb_name = 'voc_2007_trainval'\n",
    "imdb_name = 'kittipose_train'\n",
    "cfg_file = 'experiments/cfgs/faster_rcnn_end2end.yml'\n",
    "pretrained_model = '/home/pculbert/Documents/faster_rcnn_pytorch/VGG_imagenet.npy'\n",
    "output_dir = 'trained_models/saved_pose_model_test'\n",
    "\n",
    "start_step = 0\n",
    "end_step = 100000\n",
    "lr_decay_steps = {60000, 80000}\n",
    "lr_decay = 1./10\n",
    "\n",
    "rand_seed = 1024\n",
    "_DEBUG = True\n",
    "use_tensorboard = False\n",
    "remove_all_log = False   # remove all historical experiments in TensorBoard\n",
    "exp_name = None # the previous experiment name in TensorBoard\n",
    "\n",
    "# ------------\n",
    "\n",
    "if rand_seed is not None:\n",
    "    np.random.seed(rand_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load config\n",
    "cfg_from_file(cfg_file)\n",
    "lr = cfg.TRAIN.LEARNING_RATE\n",
    "momentum = cfg.TRAIN.MOMENTUM\n",
    "weight_decay = cfg.TRAIN.WEIGHT_DECAY\n",
    "disp_interval = cfg.TRAIN.DISPLAY\n",
    "log_interval = cfg.TRAIN.LOG_IMAGE_ITERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method kittipose.default_roidb of <faster_rcnn.datasets.kittipose.kittipose object at 0x7fa0bcec2390>>\n",
      "Remove empty annotations:  005066 004339 004040 003383 001752 001091 000547 Done. \n",
      "kittipose_train gt roidb loaded from /home/pculbert/Documents/faster_rcnn_pytorch/data/cache/kittipose_train_gt_roidb.pkl\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "imdb = get_imdb(imdb_name)\n",
    "rdl_roidb.prepare_roidb(imdb)\n",
    "roidb = imdb.roidb\n",
    "# roidb is a database, containing bounding box info for all training images\n",
    "data_layer = RoIDataLayer(roidb, imdb.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load net\n",
    "net = FasterRCNN(classes=imdb.classes, debug=_DEBUG)\n",
    "network.weights_normal_init(net, dev=0.01)\n",
    "network.load_pretrained_npy(net, pretrained_model)\n",
    "# model_file = '/media/longc/Data/models/VGGnet_fast_rcnn_iter_70000.h5'\n",
    "# model_file = 'models/saved_model3/faster_rcnn_60000.h5'\n",
    "# network.load_net(model_file, net)\n",
    "# exp_name = 'vgg16_02-19_13-24'\n",
    "# start_step = 60001\n",
    "#lr /= 10.\n",
    "# network.weights_normal_init([net.bbox_fc, net.score_fc, net.fc6, net.fc7], dev=0.01)\n",
    "\n",
    "net.cuda()\n",
    "net.train()\n",
    "\n",
    "params = list(net.parameters())\n",
    "# optimizer = torch.optim.Adam(params[-8:], lr=lr)\n",
    "optimizer = torch.optim.SGD(params[8:], lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# tensorboad\n",
    "use_tensorboard = use_tensorboard and CrayonClient is not None\n",
    "if use_tensorboard:\n",
    "    cc = CrayonClient(hostname='127.0.0.1')\n",
    "    if remove_all_log:\n",
    "        cc.remove_all_experiments()\n",
    "    if exp_name is None:\n",
    "        exp_name = datetime.now().strftime('vgg16_%m-%d_%H-%M')\n",
    "        exp = cc.create_experiment(exp_name)\n",
    "    else:\n",
    "        exp = cc.open_experiment(exp_name)\n",
    "        \n",
    "#for param in net.parameters():\n",
    "#    print(type(param.data), param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, image: 003871.jpg, loss: 86.8284, fps: 3.83 (0.26s per batch)\n",
      "\trpn_cls: 0.6194, rpn_box: 1.7699, rcnn_cls: 2.5218, rcnn_box: 6.5504, rcnn_pose: 0.4839\n",
      "step 1, image: 004451.jpg, loss: 208.0184, fps: 3.77 (0.27s per batch)\n",
      "\trpn_cls: 0.6366, rpn_box: 2.7274, rcnn_cls: 4.3271, rcnn_box: 17.4559, rcnn_pose: 1.2214\n",
      "step 2, image: 001085.jpg, loss: 99.3372, fps: 3.84 (0.26s per batch)\n",
      "\trpn_cls: 0.6924, rpn_box: 1.7934, rcnn_cls: 2.0870, rcnn_box: 7.8117, rcnn_pose: 0.5066\n",
      "step 3, image: 000319.jpg, loss: 102.7524, fps: 3.75 (0.27s per batch)\n",
      "\trpn_cls: 0.6838, rpn_box: 2.1854, rcnn_cls: 2.2576, rcnn_box: 7.7305, rcnn_pose: 0.6520\n",
      "step 4, image: 000343.jpg, loss: 66.2983, fps: 3.84 (0.26s per batch)\n",
      "\trpn_cls: 0.6651, rpn_box: 1.4305, rcnn_cls: 2.6542, rcnn_box: 4.8311, rcnn_pose: 0.3631\n",
      "step 5, image: 000370.jpg, loss: 63.5163, fps: 3.75 (0.27s per batch)\n",
      "\trpn_cls: 0.6723, rpn_box: 1.2220, rcnn_cls: 2.0997, rcnn_box: 4.8196, rcnn_pose: 0.3279\n",
      "step 6, image: 001054.jpg, loss: 88.2856, fps: 3.79 (0.26s per batch)\n",
      "\trpn_cls: 0.7260, rpn_box: 1.1024, rcnn_cls: 1.8399, rcnn_box: 7.4461, rcnn_pose: 0.2355\n",
      "step 7, image: 003552.jpg, loss: 84.9945, fps: 3.71 (0.27s per batch)\n",
      "\trpn_cls: 0.5650, rpn_box: 0.6231, rcnn_cls: 2.5406, rcnn_box: 7.5130, rcnn_pose: 0.5279\n",
      "step 8, image: 004832.jpg, loss: 26.2884, fps: 3.72 (0.27s per batch)\n",
      "\trpn_cls: 0.6938, rpn_box: 0.9985, rcnn_cls: 1.5200, rcnn_box: 1.3642, rcnn_pose: 0.4482\n",
      "step 9, image: 003306.jpg, loss: 26.8211, fps: 3.75 (0.27s per batch)\n",
      "\trpn_cls: 0.6369, rpn_box: 0.9408, rcnn_cls: 2.0700, rcnn_box: 1.1125, rcnn_pose: 3.5809\n",
      "step 10, image: 004505.jpg, loss: 30.2695, fps: 3.75 (0.27s per batch)\n",
      "\trpn_cls: 0.6727, rpn_box: 2.1570, rcnn_cls: 1.6438, rcnn_box: 0.1752, rcnn_pose: 4.6302\n",
      "step 11, image: 005835.jpg, loss: 37.5140, fps: 3.72 (0.27s per batch)\n",
      "\trpn_cls: 0.6287, rpn_box: 0.1055, rcnn_cls: 2.5123, rcnn_box: 3.0397, rcnn_pose: 2.9218\n",
      "step 12, image: 000952.jpg, loss: 44.2074, fps: 3.76 (0.27s per batch)\n",
      "\trpn_cls: 0.6379, rpn_box: 0.1210, rcnn_cls: 1.4405, rcnn_box: 4.0832, rcnn_pose: 0.0872\n",
      "step 13, image: 002172.jpg, loss: 20.9808, fps: 3.76 (0.27s per batch)\n",
      "\trpn_cls: 0.6668, rpn_box: 1.1097, rcnn_cls: 1.3822, rcnn_box: 0.7580, rcnn_pose: 0.2548\n",
      "step 14, image: 005515.jpg, loss: 29.9527, fps: 3.65 (0.27s per batch)\n",
      "\trpn_cls: 0.6609, rpn_box: 0.5703, rcnn_cls: 1.5823, rcnn_box: 2.1771, rcnn_pose: 0.2355\n",
      "step 15, image: 004777.jpg, loss: 19.9788, fps: 3.71 (0.27s per batch)\n",
      "\trpn_cls: 0.6739, rpn_box: 1.6617, rcnn_cls: 1.4478, rcnn_box: 0.0317, rcnn_pose: 0.9239\n",
      "step 16, image: 004545.jpg, loss: 16.6246, fps: 3.70 (0.27s per batch)\n",
      "\trpn_cls: 0.6747, rpn_box: 1.1206, rcnn_cls: 1.2961, rcnn_box: 0.3191, rcnn_pose: 0.2569\n",
      "step 17, image: 005796.jpg, loss: 16.6739, fps: 3.79 (0.26s per batch)\n",
      "\trpn_cls: 0.6826, rpn_box: 1.2961, rcnn_cls: 1.4467, rcnn_box: 0.0477, rcnn_pose: 1.1061\n",
      "step 18, image: 004887.jpg, loss: 15.4839, fps: 3.80 (0.26s per batch)\n",
      "\trpn_cls: 0.6804, rpn_box: 1.0856, rcnn_cls: 1.2818, rcnn_box: 0.2529, rcnn_pose: 0.1366\n",
      "step 19, image: 004061.jpg, loss: 16.9127, fps: 3.65 (0.27s per batch)\n",
      "\trpn_cls: 0.6660, rpn_box: 1.3644, rcnn_cls: 1.2996, rcnn_box: 0.0099, rcnn_pose: 1.2034\n",
      "step 20, image: 004728.jpg, loss: 8.4756, fps: 3.76 (0.27s per batch)\n",
      "\trpn_cls: 0.6551, rpn_box: 0.5766, rcnn_cls: 1.2589, rcnn_box: 0.0355, rcnn_pose: 0.4401\n",
      "step 21, image: 005493.jpg, loss: 15.4101, fps: 3.75 (0.27s per batch)\n",
      "\trpn_cls: 0.6746, rpn_box: 0.9736, rcnn_cls: 1.1882, rcnn_box: 0.3553, rcnn_pose: 0.2589\n",
      "step 22, image: 003289.jpg, loss: 13.1293, fps: 3.67 (0.27s per batch)\n",
      "\trpn_cls: 0.7082, rpn_box: 1.0494, rcnn_cls: 1.2054, rcnn_box: 0.0190, rcnn_pose: 0.5315\n",
      "step 23, image: 001832.jpg, loss: 6.7734, fps: 3.73 (0.27s per batch)\n",
      "\trpn_cls: 0.6441, rpn_box: 0.0301, rcnn_cls: 1.0946, rcnn_box: 0.4403, rcnn_pose: 0.3306\n",
      "step 24, image: 003694.jpg, loss: 12.0321, fps: 3.80 (0.26s per batch)\n",
      "\trpn_cls: 0.6428, rpn_box: 0.1431, rcnn_cls: 1.1756, rcnn_box: 0.5394, rcnn_pose: 3.3893\n",
      "step 25, image: 002200.jpg, loss: 18.3325, fps: 3.74 (0.27s per batch)\n",
      "\trpn_cls: 0.6849, rpn_box: 1.5797, rcnn_cls: 1.1335, rcnn_box: 0.0237, rcnn_pose: 0.4795\n",
      "step 26, image: 005541.jpg, loss: 13.4929, fps: 3.73 (0.27s per batch)\n",
      "\trpn_cls: 0.6805, rpn_box: 1.0093, rcnn_cls: 1.1792, rcnn_box: 0.1083, rcnn_pose: 0.4565\n",
      "step 27, image: 001029.jpg, loss: 9.6154, fps: 3.80 (0.26s per batch)\n",
      "\trpn_cls: 0.6407, rpn_box: 0.0783, rcnn_cls: 1.2909, rcnn_box: 0.2896, rcnn_pose: 4.0049\n",
      "step 28, image: 000644.jpg, loss: 20.3525, fps: 3.76 (0.27s per batch)\n",
      "\trpn_cls: 0.6953, rpn_box: 1.7831, rcnn_cls: 1.0911, rcnn_box: 0.0005, rcnn_pose: 0.7302\n",
      "step 29, image: 004791.jpg, loss: 16.4082, fps: 3.72 (0.27s per batch)\n",
      "\trpn_cls: 0.6607, rpn_box: 1.2786, rcnn_cls: 1.0375, rcnn_box: 0.0006, rcnn_pose: 1.9179\n",
      "step 30, image: 002189.jpg, loss: 13.2744, fps: 3.68 (0.27s per batch)\n",
      "\trpn_cls: 0.6768, rpn_box: 1.0287, rcnn_cls: 1.0862, rcnn_box: 0.0004, rcnn_pose: 1.2200\n",
      "step 31, image: 000650.jpg, loss: 16.1973, fps: 3.65 (0.27s per batch)\n",
      "\trpn_cls: 0.6798, rpn_box: 1.3220, rcnn_cls: 1.0741, rcnn_box: 0.0006, rcnn_pose: 1.2167\n",
      "step 32, image: 003751.jpg, loss: 10.8050, fps: 3.62 (0.28s per batch)\n",
      "\trpn_cls: 0.6450, rpn_box: 0.4181, rcnn_cls: 1.0483, rcnn_box: 0.3872, rcnn_pose: 1.0587\n",
      "step 33, image: 005793.jpg, loss: 19.3102, fps: 3.50 (0.29s per batch)\n",
      "\trpn_cls: 0.6428, rpn_box: 0.5559, rcnn_cls: 1.5482, rcnn_box: 1.1292, rcnn_pose: 0.2683\n",
      "step 34, image: 003638.jpg, loss: 12.0652, fps: 3.68 (0.27s per batch)\n",
      "\trpn_cls: 0.6622, rpn_box: 0.4777, rcnn_cls: 1.1420, rcnn_box: 0.3791, rcnn_pose: 1.6933\n",
      "step 35, image: 002022.jpg, loss: 9.7608, fps: 3.77 (0.26s per batch)\n",
      "\trpn_cls: 0.6755, rpn_box: 0.7093, rcnn_cls: 1.0487, rcnn_box: 0.0250, rcnn_pose: 0.6932\n",
      "step 36, image: 005089.jpg, loss: 8.8465, fps: 3.77 (0.27s per batch)\n",
      "\trpn_cls: 0.6838, rpn_box: 0.6031, rcnn_cls: 1.1660, rcnn_box: 0.0790, rcnn_pose: 0.1754\n",
      "step 37, image: 004497.jpg, loss: 8.9153, fps: 3.73 (0.27s per batch)\n",
      "\trpn_cls: 0.6543, rpn_box: 0.4311, rcnn_cls: 0.9397, rcnn_box: 0.0031, rcnn_pose: 2.9796\n",
      "step 38, image: 002545.jpg, loss: 6.4158, fps: 3.81 (0.26s per batch)\n",
      "\trpn_cls: 0.6605, rpn_box: 0.1244, rcnn_cls: 1.2385, rcnn_box: 0.3044, rcnn_pose: 0.2295\n",
      "step 39, image: 004551.jpg, loss: 12.3369, fps: 3.81 (0.26s per batch)\n",
      "\trpn_cls: 0.6942, rpn_box: 0.9467, rcnn_cls: 1.0055, rcnn_box: 0.0777, rcnn_pose: 0.3936\n",
      "step 40, image: 005429.jpg, loss: 11.5090, fps: 3.79 (0.26s per batch)\n",
      "\trpn_cls: 0.6806, rpn_box: 0.1636, rcnn_cls: 1.2001, rcnn_box: 0.0707, rcnn_pose: 7.2849\n",
      "step 41, image: 001557.jpg, loss: 11.9732, fps: 3.80 (0.26s per batch)\n",
      "\trpn_cls: 0.6839, rpn_box: 0.8898, rcnn_cls: 1.1514, rcnn_box: 0.0965, rcnn_pose: 0.2756\n",
      "step 42, image: 001283.jpg, loss: 18.0008, fps: 3.74 (0.27s per batch)\n",
      "\trpn_cls: 0.6859, rpn_box: 1.5048, rcnn_cls: 1.1747, rcnn_box: 0.0005, rcnn_pose: 1.0874\n",
      "step 43, image: 001960.jpg, loss: 10.9295, fps: 3.67 (0.27s per batch)\n",
      "\trpn_cls: 0.6851, rpn_box: 0.8631, rcnn_cls: 1.1296, rcnn_box: 0.0005, rcnn_pose: 0.4788\n",
      "step 44, image: 000672.jpg, loss: 14.0589, fps: 3.73 (0.27s per batch)\n",
      "\trpn_cls: 0.6774, rpn_box: 1.1100, rcnn_cls: 1.0951, rcnn_box: 0.0870, rcnn_pose: 0.3164\n",
      "step 45, image: 003336.jpg, loss: 22.0809, fps: 3.79 (0.26s per batch)\n",
      "\trpn_cls: 0.6525, rpn_box: 1.4360, rcnn_cls: 0.8968, rcnn_box: 0.0002, rcnn_pose: 6.1705\n",
      "step 46, image: 000648.jpg, loss: 27.5431, fps: 3.80 (0.26s per batch)\n",
      "\trpn_cls: 0.6166, rpn_box: 1.0025, rcnn_cls: 2.1626, rcnn_box: 1.1934, rcnn_pose: 2.8046\n",
      "step 47, image: 002273.jpg, loss: 22.1921, fps: 3.68 (0.27s per batch)\n",
      "\trpn_cls: 0.5934, rpn_box: 0.8632, rcnn_cls: 2.1693, rcnn_box: 0.8010, rcnn_pose: 2.7876\n",
      "step 48, image: 002378.jpg, loss: 47.8280, fps: 3.77 (0.27s per batch)\n",
      "\trpn_cls: 0.6042, rpn_box: 2.9870, rcnn_cls: 2.5518, rcnn_box: 1.4601, rcnn_pose: 0.2008\n",
      "step 49, image: 002152.jpg, loss: 47.2522, fps: 3.78 (0.26s per batch)\n",
      "\trpn_cls: 0.6434, rpn_box: 3.0760, rcnn_cls: 2.4427, rcnn_box: 1.3312, rcnn_pose: 0.0936\n",
      "step 50, image: 000096.jpg, loss: 12.2904, fps: 3.82 (0.26s per batch)\n",
      "\trpn_cls: 0.6205, rpn_box: 0.7255, rcnn_cls: 1.2784, rcnn_box: 0.2888, rcnn_pose: 0.2483\n",
      "step 51, image: 003591.jpg, loss: 28.1088, fps: 3.82 (0.26s per batch)\n",
      "\trpn_cls: 0.6380, rpn_box: 0.6524, rcnn_cls: 2.3641, rcnn_box: 1.2940, rcnn_pose: 5.6423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 52, image: 003351.jpg, loss: 16.7684, fps: 3.76 (0.27s per batch)\n",
      "\trpn_cls: 0.6579, rpn_box: 1.3209, rcnn_cls: 0.8977, rcnn_box: 0.0166, rcnn_pose: 1.8374\n",
      "step 53, image: 004034.jpg, loss: 11.7006, fps: 3.73 (0.27s per batch)\n",
      "\trpn_cls: 0.6593, rpn_box: 0.4113, rcnn_cls: 1.2817, rcnn_box: 0.2788, rcnn_pose: 2.8582\n",
      "step 54, image: 004478.jpg, loss: 13.4919, fps: 3.78 (0.26s per batch)\n",
      "\trpn_cls: 0.6742, rpn_box: 1.0203, rcnn_cls: 1.0453, rcnn_box: 0.1057, rcnn_pose: 0.5123\n",
      "step 55, image: 001060.jpg, loss: 17.9815, fps: 3.27 (0.31s per batch)\n",
      "\trpn_cls: 0.6683, rpn_box: 1.4697, rcnn_cls: 1.0363, rcnn_box: 0.1134, rcnn_pose: 0.4463\n",
      "step 56, image: 000743.jpg, loss: 20.6616, fps: 3.58 (0.28s per batch)\n",
      "\trpn_cls: 0.6740, rpn_box: 1.7408, rcnn_cls: 0.9735, rcnn_box: 0.0698, rcnn_pose: 0.9082\n",
      "step 57, image: 004667.jpg, loss: 6.4977, fps: 3.69 (0.27s per batch)\n",
      "\trpn_cls: 0.6622, rpn_box: 0.3349, rcnn_cls: 0.8928, rcnn_box: 0.0711, rcnn_pose: 0.8824\n",
      "step 58, image: 005833.jpg, loss: 10.0832, fps: 3.76 (0.27s per batch)\n",
      "\trpn_cls: 0.6629, rpn_box: 0.7085, rcnn_cls: 1.0494, rcnn_box: 0.0968, rcnn_pose: 0.3172\n",
      "step 59, image: 003271.jpg, loss: 7.8310, fps: 3.74 (0.27s per batch)\n",
      "\trpn_cls: 0.6229, rpn_box: 0.3475, rcnn_cls: 1.1866, rcnn_box: 0.2305, rcnn_pose: 0.2416\n",
      "step 60, image: 003788.jpg, loss: 30.5143, fps: 3.74 (0.27s per batch)\n",
      "\trpn_cls: 0.6085, rpn_box: 0.8016, rcnn_cls: 2.0706, rcnn_box: 1.7108, rcnn_pose: 2.7104\n",
      "step 61, image: 005058.jpg, loss: 13.0361, fps: 3.75 (0.27s per batch)\n",
      "\trpn_cls: 0.6404, rpn_box: 0.5938, rcnn_cls: 1.5087, rcnn_box: 0.4754, rcnn_pose: 0.1950\n",
      "step 62, image: 004160.jpg, loss: 10.9304, fps: 3.80 (0.26s per batch)\n",
      "\trpn_cls: 0.6318, rpn_box: 0.6280, rcnn_cls: 1.0722, rcnn_box: 0.2748, rcnn_pose: 0.1983\n",
      "step 63, image: 002362.jpg, loss: 10.7473, fps: 3.72 (0.27s per batch)\n",
      "\trpn_cls: 0.6487, rpn_box: 0.4284, rcnn_cls: 1.5855, rcnn_box: 0.3711, rcnn_pose: 0.5186\n",
      "step 64, image: 004847.jpg, loss: 10.8942, fps: 3.74 (0.27s per batch)\n",
      "\trpn_cls: 0.6427, rpn_box: 0.5528, rcnn_cls: 1.0109, rcnn_box: 0.1144, rcnn_pose: 2.5687\n",
      "step 65, image: 001766.jpg, loss: 16.3962, fps: 3.75 (0.27s per batch)\n",
      "\trpn_cls: 0.6530, rpn_box: 1.2729, rcnn_cls: 0.9319, rcnn_box: 0.1544, rcnn_pose: 0.5380\n",
      "step 66, image: 003896.jpg, loss: 12.4807, fps: 3.76 (0.27s per batch)\n",
      "\trpn_cls: 0.6412, rpn_box: 0.7572, rcnn_cls: 1.0335, rcnn_box: 0.3031, rcnn_pose: 0.2028\n",
      "step 67, image: 002361.jpg, loss: 5.4272, fps: 3.75 (0.27s per batch)\n",
      "\trpn_cls: 0.6263, rpn_box: 0.0905, rcnn_cls: 1.0276, rcnn_box: 0.2732, rcnn_pose: 0.1357\n",
      "step 68, image: 001441.jpg, loss: 8.7227, fps: 3.81 (0.26s per batch)\n",
      "\trpn_cls: 0.6219, rpn_box: 0.0339, rcnn_cls: 1.4070, rcnn_box: 0.3159, rcnn_pose: 3.1956\n",
      "step 69, image: 004260.jpg, loss: 9.2051, fps: 3.76 (0.27s per batch)\n",
      "\trpn_cls: 0.6095, rpn_box: 0.5667, rcnn_cls: 0.8992, rcnn_box: 0.1942, rcnn_pose: 0.0868\n",
      "step 70, image: 001823.jpg, loss: 7.4286, fps: 3.79 (0.26s per batch)\n",
      "\trpn_cls: 0.6392, rpn_box: 0.5207, rcnn_cls: 0.9389, rcnn_box: 0.0102, rcnn_pose: 0.5409\n",
      "step 71, image: 005754.jpg, loss: 9.7274, fps: 3.73 (0.27s per batch)\n",
      "\trpn_cls: 0.6543, rpn_box: 0.6592, rcnn_cls: 0.9802, rcnn_box: 0.1378, rcnn_pose: 0.1220\n",
      "step 72, image: 004768.jpg, loss: 21.8766, fps: 3.69 (0.27s per batch)\n",
      "\trpn_cls: 0.6493, rpn_box: 1.4341, rcnn_cls: 0.9904, rcnn_box: 0.0005, rcnn_pose: 5.8912\n",
      "step 73, image: 000018.jpg, loss: 18.4563, fps: 3.79 (0.26s per batch)\n",
      "\trpn_cls: 0.6315, rpn_box: 0.9560, rcnn_cls: 0.9592, rcnn_box: 0.0014, rcnn_pose: 7.2917\n",
      "step 74, image: 003091.jpg, loss: 10.0069, fps: 3.72 (0.27s per batch)\n",
      "\trpn_cls: 0.6420, rpn_box: 0.5972, rcnn_cls: 0.9505, rcnn_box: 0.2301, rcnn_pose: 0.1414\n",
      "step 75, image: 005453.jpg, loss: 7.9007, fps: 3.80 (0.26s per batch)\n",
      "\trpn_cls: 0.6290, rpn_box: 0.3386, rcnn_cls: 1.0495, rcnn_box: 0.2692, rcnn_pose: 0.1432\n",
      "step 76, image: 003347.jpg, loss: 13.9997, fps: 3.79 (0.26s per batch)\n",
      "\trpn_cls: 0.6191, rpn_box: 0.3948, rcnn_cls: 0.8468, rcnn_box: 0.5054, rcnn_pose: 3.5319\n",
      "step 77, image: 002070.jpg, loss: 8.3161, fps: 3.79 (0.26s per batch)\n",
      "\trpn_cls: 0.6047, rpn_box: 0.3931, rcnn_cls: 0.9515, rcnn_box: 0.2476, rcnn_pose: 0.3528\n",
      "step 78, image: 002391.jpg, loss: 11.7580, fps: 3.81 (0.26s per batch)\n",
      "\trpn_cls: 0.6042, rpn_box: 0.2550, rcnn_cls: 0.8944, rcnn_box: 0.0305, rcnn_pose: 7.4052\n",
      "step 79, image: 000996.jpg, loss: 3.7391, fps: 3.78 (0.26s per batch)\n",
      "\trpn_cls: 0.6279, rpn_box: 0.0720, rcnn_cls: 0.9157, rcnn_box: 0.1348, rcnn_pose: 0.1272\n",
      "step 80, image: 003354.jpg, loss: 4.7189, fps: 3.80 (0.26s per batch)\n",
      "\trpn_cls: 0.6151, rpn_box: 0.1372, rcnn_cls: 0.8434, rcnn_box: 0.1090, rcnn_pose: 0.7982\n",
      "step 81, image: 004657.jpg, loss: 8.6105, fps: 3.70 (0.27s per batch)\n",
      "\trpn_cls: 0.6400, rpn_box: 0.3628, rcnn_cls: 1.4761, rcnn_box: 0.2372, rcnn_pose: 0.4940\n",
      "step 82, image: 002961.jpg, loss: 7.0675, fps: 3.64 (0.27s per batch)\n",
      "\trpn_cls: 0.6274, rpn_box: 0.4027, rcnn_cls: 0.8897, rcnn_box: 0.1021, rcnn_pose: 0.5029\n",
      "step 83, image: 000923.jpg, loss: 13.0364, fps: 3.40 (0.29s per batch)\n",
      "\trpn_cls: 0.6289, rpn_box: 0.3623, rcnn_cls: 1.4659, rcnn_box: 0.3123, rcnn_pose: 4.1953\n",
      "step 84, image: 001096.jpg, loss: 5.2885, fps: 3.66 (0.27s per batch)\n",
      "\trpn_cls: 0.6200, rpn_box: 0.2405, rcnn_cls: 0.9259, rcnn_box: 0.1128, rcnn_pose: 0.2090\n",
      "step 85, image: 005870.jpg, loss: 6.2191, fps: 3.73 (0.27s per batch)\n",
      "\trpn_cls: 0.6090, rpn_box: 0.3032, rcnn_cls: 0.9265, rcnn_box: 0.1411, rcnn_pose: 0.2402\n",
      "step 86, image: 002387.jpg, loss: 6.4013, fps: 3.75 (0.27s per batch)\n",
      "\trpn_cls: 0.6246, rpn_box: 0.3174, rcnn_cls: 0.8632, rcnn_box: 0.1281, rcnn_pose: 0.4587\n",
      "step 87, image: 001920.jpg, loss: 9.7505, fps: 3.65 (0.27s per batch)\n",
      "\trpn_cls: 0.6002, rpn_box: 0.2191, rcnn_cls: 1.2376, rcnn_box: 0.2843, rcnn_pose: 2.8786\n",
      "step 88, image: 003654.jpg, loss: 6.2160, fps: 3.77 (0.27s per batch)\n",
      "\trpn_cls: 0.6276, rpn_box: 0.2138, rcnn_cls: 0.9989, rcnn_box: 0.1268, rcnn_pose: 1.1835\n",
      "step 89, image: 003018.jpg, loss: 4.6976, fps: 3.74 (0.27s per batch)\n",
      "\trpn_cls: 0.6398, rpn_box: 0.1132, rcnn_cls: 1.2768, rcnn_box: 0.1253, rcnn_pose: 0.3963\n",
      "step 90, image: 005705.jpg, loss: 7.9725, fps: 3.80 (0.26s per batch)\n",
      "\trpn_cls: 0.6383, rpn_box: 0.4838, rcnn_cls: 0.9664, rcnn_box: 0.1282, rcnn_pose: 0.2469\n",
      "step 91, image: 005328.jpg, loss: 18.2382, fps: 3.71 (0.27s per batch)\n",
      "\trpn_cls: 0.6229, rpn_box: 1.2505, rcnn_cls: 0.9152, rcnn_box: 0.1267, rcnn_pose: 2.9275\n",
      "step 92, image: 004531.jpg, loss: 3.3985, fps: 3.77 (0.27s per batch)\n",
      "\trpn_cls: 0.5945, rpn_box: 0.0406, rcnn_cls: 0.9161, rcnn_box: 0.1290, rcnn_pose: 0.1914\n",
      "step 93, image: 000274.jpg, loss: 5.0544, fps: 3.71 (0.27s per batch)\n",
      "\trpn_cls: 0.6610, rpn_box: 0.2463, rcnn_cls: 0.9529, rcnn_box: 0.0605, rcnn_pose: 0.3720\n",
      "step 94, image: 004909.jpg, loss: 7.7985, fps: 3.66 (0.27s per batch)\n",
      "\trpn_cls: 0.6546, rpn_box: 0.4714, rcnn_cls: 0.9814, rcnn_box: 0.1368, rcnn_pose: 0.0802\n",
      "step 95, image: 000244.jpg, loss: 5.8021, fps: 3.74 (0.27s per batch)\n",
      "\trpn_cls: 0.6364, rpn_box: 0.2313, rcnn_cls: 0.9709, rcnn_box: 0.1811, rcnn_pose: 0.0707\n",
      "step 96, image: 003936.jpg, loss: 6.8805, fps: 3.73 (0.27s per batch)\n",
      "\trpn_cls: 0.5954, rpn_box: 0.3908, rcnn_cls: 0.9679, rcnn_box: 0.0841, rcnn_pose: 0.5685\n",
      "step 97, image: 000316.jpg, loss: 5.6326, fps: 3.72 (0.27s per batch)\n",
      "\trpn_cls: 0.6316, rpn_box: 0.3019, rcnn_cls: 0.9858, rcnn_box: 0.0909, rcnn_pose: 0.0873\n",
      "step 98, image: 003371.jpg, loss: 4.9888, fps: 3.77 (0.27s per batch)\n",
      "\trpn_cls: 0.6133, rpn_box: 0.1961, rcnn_cls: 0.9418, rcnn_box: 0.1130, rcnn_pose: 0.3423\n",
      "step 99, image: 000349.jpg, loss: 3.8302, fps: 3.73 (0.27s per batch)\n",
      "\trpn_cls: 0.6009, rpn_box: 0.1190, rcnn_cls: 0.9341, rcnn_box: 0.0981, rcnn_pose: 0.1240\n",
      "step 100, image: 005634.jpg, loss: 5.8409, fps: 3.63 (0.28s per batch)\n",
      "\trpn_cls: 0.6099, rpn_box: 0.3075, rcnn_cls: 0.9271, rcnn_box: 0.1005, rcnn_pose: 0.2243\n",
      "step 101, image: 002477.jpg, loss: 9.5283, fps: 3.68 (0.27s per batch)\n",
      "\trpn_cls: 0.6140, rpn_box: 0.5667, rcnn_cls: 1.4434, rcnn_box: 0.1321, rcnn_pose: 0.4832\n",
      "step 102, image: 005638.jpg, loss: 7.2270, fps: 3.79 (0.26s per batch)\n",
      "\trpn_cls: 0.5722, rpn_box: 0.0587, rcnn_cls: 0.8467, rcnn_box: 0.0749, rcnn_pose: 4.4715\n",
      "step 103, image: 004582.jpg, loss: 9.7477, fps: 3.73 (0.27s per batch)\n",
      "\trpn_cls: 0.5894, rpn_box: 0.4731, rcnn_cls: 0.9069, rcnn_box: 0.0988, rcnn_pose: 2.5332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 104, image: 000512.jpg, loss: 7.8717, fps: 3.81 (0.26s per batch)\n",
      "\trpn_cls: 0.5660, rpn_box: 0.0647, rcnn_cls: 0.8386, rcnn_box: 0.1118, rcnn_pose: 4.7024\n",
      "step 105, image: 000891.jpg, loss: 7.9640, fps: 3.71 (0.27s per batch)\n",
      "\trpn_cls: 0.5801, rpn_box: 0.1276, rcnn_cls: 0.8452, rcnn_box: 0.2048, rcnn_pose: 3.2142\n",
      "step 106, image: 003828.jpg, loss: 4.3374, fps: 3.79 (0.26s per batch)\n",
      "\trpn_cls: 0.6025, rpn_box: 0.1361, rcnn_cls: 0.9250, rcnn_box: 0.1011, rcnn_pose: 0.4379\n",
      "step 107, image: 003280.jpg, loss: 6.4161, fps: 3.71 (0.27s per batch)\n",
      "\trpn_cls: 0.6475, rpn_box: 0.3926, rcnn_cls: 1.0224, rcnn_box: 0.0670, rcnn_pose: 0.1502\n",
      "step 108, image: 005123.jpg, loss: 10.8121, fps: 3.71 (0.27s per batch)\n",
      "\trpn_cls: 0.6331, rpn_box: 0.8287, rcnn_cls: 0.9671, rcnn_box: 0.0726, rcnn_pose: 0.1995\n",
      "step 109, image: 003688.jpg, loss: 11.9476, fps: 3.71 (0.27s per batch)\n",
      "\trpn_cls: 0.6479, rpn_box: 0.8539, rcnn_cls: 1.2885, rcnn_box: 0.0289, rcnn_pose: 1.1833\n",
      "step 110, image: 002511.jpg, loss: 4.4789, fps: 3.71 (0.27s per batch)\n",
      "\trpn_cls: 0.6005, rpn_box: 0.1270, rcnn_cls: 0.9456, rcnn_box: 0.1404, rcnn_pose: 0.2588\n",
      "step 111, image: 002081.jpg, loss: 5.3903, fps: 3.74 (0.27s per batch)\n",
      "\trpn_cls: 0.6130, rpn_box: 0.2509, rcnn_cls: 0.9411, rcnn_box: 0.1110, rcnn_pose: 0.2175\n",
      "step 112, image: 004850.jpg, loss: 10.4856, fps: 3.75 (0.27s per batch)\n",
      "\trpn_cls: 0.6140, rpn_box: 0.6999, rcnn_cls: 1.1933, rcnn_box: 0.1448, rcnn_pose: 0.2315\n",
      "step 113, image: 002038.jpg, loss: 6.0747, fps: 3.77 (0.27s per batch)\n",
      "\trpn_cls: 0.6042, rpn_box: 0.3382, rcnn_cls: 0.9367, rcnn_box: 0.0953, rcnn_pose: 0.1978\n",
      "step 114, image: 000811.jpg, loss: 11.2733, fps: 3.72 (0.27s per batch)\n",
      "\trpn_cls: 0.6233, rpn_box: 0.4436, rcnn_cls: 1.3867, rcnn_box: 0.1184, rcnn_pose: 3.6433\n",
      "step 115, image: 001601.jpg, loss: 12.7350, fps: 3.76 (0.27s per batch)\n",
      "\trpn_cls: 0.6302, rpn_box: 1.0044, rcnn_cls: 0.9556, rcnn_box: 0.0647, rcnn_pose: 0.4583\n",
      "step 116, image: 005798.jpg, loss: 7.9719, fps: 3.76 (0.27s per batch)\n",
      "\trpn_cls: 0.6371, rpn_box: 0.5712, rcnn_cls: 0.9567, rcnn_box: 0.0391, rcnn_pose: 0.2757\n",
      "step 117, image: 003358.jpg, loss: 6.6094, fps: 3.74 (0.27s per batch)\n",
      "\trpn_cls: 0.6119, rpn_box: 0.2921, rcnn_cls: 0.8384, rcnn_box: 0.0788, rcnn_pose: 1.4493\n",
      "step 118, image: 003782.jpg, loss: 5.7850, fps: 3.81 (0.26s per batch)\n",
      "\trpn_cls: 0.6382, rpn_box: 0.3115, rcnn_cls: 0.9318, rcnn_box: 0.0980, rcnn_pose: 0.1203\n",
      "step 119, image: 005117.jpg, loss: 6.9354, fps: 3.74 (0.27s per batch)\n",
      "\trpn_cls: 0.5577, rpn_box: 0.3795, rcnn_cls: 0.7616, rcnn_box: 0.1278, rcnn_pose: 0.5427\n",
      "step 120, image: 000904.jpg, loss: 6.2633, fps: 3.79 (0.26s per batch)\n",
      "\trpn_cls: 0.5570, rpn_box: 0.2958, rcnn_cls: 0.7909, rcnn_box: 0.1174, rcnn_pose: 0.7834\n",
      "step 121, image: 005656.jpg, loss: 7.2444, fps: 3.78 (0.26s per batch)\n",
      "\trpn_cls: 0.5770, rpn_box: 0.4100, rcnn_cls: 1.0409, rcnn_box: 0.0634, rcnn_pose: 0.8928\n",
      "step 122, image: 002096.jpg, loss: 6.1427, fps: 3.81 (0.26s per batch)\n",
      "\trpn_cls: 0.5933, rpn_box: 0.3485, rcnn_cls: 0.9439, rcnn_box: 0.0947, rcnn_pose: 0.1735\n",
      "step 123, image: 000643.jpg, loss: 4.8955, fps: 3.78 (0.26s per batch)\n",
      "\trpn_cls: 0.6128, rpn_box: 0.1921, rcnn_cls: 0.8778, rcnn_box: 0.1397, rcnn_pose: 0.0868\n",
      "step 124, image: 004128.jpg, loss: 5.5218, fps: 3.70 (0.27s per batch)\n",
      "\trpn_cls: 0.6064, rpn_box: 0.2767, rcnn_cls: 0.9197, rcnn_box: 0.1064, rcnn_pose: 0.1643\n",
      "step 125, image: 000111.jpg, loss: 5.5418, fps: 3.78 (0.26s per batch)\n",
      "\trpn_cls: 0.6245, rpn_box: 0.3114, rcnn_cls: 0.9038, rcnn_box: 0.0796, rcnn_pose: 0.1028\n",
      "step 126, image: 000720.jpg, loss: 8.1129, fps: 3.75 (0.27s per batch)\n",
      "\trpn_cls: 0.6025, rpn_box: 0.4211, rcnn_cls: 1.3633, rcnn_box: 0.0842, rcnn_pose: 1.0935\n",
      "step 127, image: 000524.jpg, loss: 6.7386, fps: 3.76 (0.27s per batch)\n",
      "\trpn_cls: 0.5942, rpn_box: 0.2986, rcnn_cls: 0.8871, rcnn_box: 0.1330, rcnn_pose: 0.9412\n",
      "step 128, image: 005432.jpg, loss: 6.9106, fps: 3.82 (0.26s per batch)\n",
      "\trpn_cls: 0.6063, rpn_box: 0.3707, rcnn_cls: 0.9216, rcnn_box: 0.0581, rcnn_pose: 1.0945\n",
      "step 129, image: 005808.jpg, loss: 16.0783, fps: 3.81 (0.26s per batch)\n",
      "\trpn_cls: 0.5640, rpn_box: 0.5083, rcnn_cls: 1.3698, rcnn_box: 0.0375, rcnn_pose: 8.6868\n",
      "step 130, image: 003922.jpg, loss: 21.5401, fps: 3.81 (0.26s per batch)\n",
      "\trpn_cls: 0.5672, rpn_box: 0.8268, rcnn_cls: 1.3664, rcnn_box: 0.0700, rcnn_pose: 10.6386\n",
      "step 131, image: 004286.jpg, loss: 5.0529, fps: 3.80 (0.26s per batch)\n",
      "\trpn_cls: 0.5821, rpn_box: 0.2241, rcnn_cls: 0.8808, rcnn_box: 0.1071, rcnn_pose: 0.2780\n",
      "step 132, image: 001511.jpg, loss: 5.7242, fps: 3.75 (0.27s per batch)\n",
      "\trpn_cls: 0.5789, rpn_box: 0.1450, rcnn_cls: 0.8558, rcnn_box: 0.0555, rcnn_pose: 2.2847\n",
      "step 133, image: 001784.jpg, loss: 4.4447, fps: 3.74 (0.27s per batch)\n",
      "\trpn_cls: 0.5818, rpn_box: 0.1490, rcnn_cls: 0.9272, rcnn_box: 0.1244, rcnn_pose: 0.2025\n",
      "step 134, image: 003743.jpg, loss: 23.5378, fps: 3.79 (0.26s per batch)\n",
      "\trpn_cls: 0.5800, rpn_box: 1.3770, rcnn_cls: 0.9168, rcnn_box: 0.0246, rcnn_pose: 8.0250\n",
      "step 135, image: 004002.jpg, loss: 7.7222, fps: 3.76 (0.27s per batch)\n",
      "\trpn_cls: 0.6011, rpn_box: 0.3482, rcnn_cls: 1.4103, rcnn_box: 0.0261, rcnn_pose: 1.9677\n",
      "step 136, image: 004819.jpg, loss: 4.8013, fps: 3.84 (0.26s per batch)\n",
      "\trpn_cls: 0.5631, rpn_box: 0.2585, rcnn_cls: 0.8153, rcnn_box: 0.0242, rcnn_pose: 0.5958\n",
      "step 137, image: 005202.jpg, loss: 6.2203, fps: 3.80 (0.26s per batch)\n",
      "\trpn_cls: 0.5667, rpn_box: 0.2319, rcnn_cls: 0.8424, rcnn_box: 0.0417, rcnn_pose: 2.0746\n",
      "step 138, image: 005957.jpg, loss: 4.5182, fps: 3.77 (0.27s per batch)\n",
      "\trpn_cls: 0.5979, rpn_box: 0.2081, rcnn_cls: 0.8396, rcnn_box: 0.0906, rcnn_pose: 0.0935\n",
      "step 139, image: 005909.jpg, loss: 6.3559, fps: 3.79 (0.26s per batch)\n",
      "\trpn_cls: 0.5658, rpn_box: 0.3764, rcnn_cls: 0.8031, rcnn_box: 0.0969, rcnn_pose: 0.2537\n",
      "step 140, image: 003057.jpg, loss: 6.9578, fps: 3.73 (0.27s per batch)\n",
      "\trpn_cls: 0.5200, rpn_box: 0.2485, rcnn_cls: 0.6998, rcnn_box: 0.0799, rcnn_pose: 2.4542\n",
      "step 141, image: 003365.jpg, loss: 5.7549, fps: 3.80 (0.26s per batch)\n",
      "\trpn_cls: 0.5226, rpn_box: 0.0638, rcnn_cls: 0.8345, rcnn_box: 0.0714, rcnn_pose: 3.0453\n",
      "step 142, image: 001128.jpg, loss: 10.3656, fps: 3.73 (0.27s per batch)\n",
      "\trpn_cls: 0.5521, rpn_box: 0.7743, rcnn_cls: 0.8150, rcnn_box: 0.1067, rcnn_pose: 0.1885\n",
      "step 143, image: 001911.jpg, loss: 8.6661, fps: 3.77 (0.27s per batch)\n",
      "\trpn_cls: 0.5373, rpn_box: 0.4242, rcnn_cls: 1.3839, rcnn_box: 0.0738, rcnn_pose: 1.7653\n",
      "step 144, image: 005160.jpg, loss: 5.1668, fps: 3.81 (0.26s per batch)\n",
      "\trpn_cls: 0.6202, rpn_box: 0.2843, rcnn_cls: 0.8995, rcnn_box: 0.0700, rcnn_pose: 0.1034\n",
      "step 145, image: 003180.jpg, loss: 7.8537, fps: 3.77 (0.26s per batch)\n",
      "\trpn_cls: 0.5807, rpn_box: 0.5013, rcnn_cls: 0.8926, rcnn_box: 0.0922, rcnn_pose: 0.4453\n",
      "step 146, image: 001243.jpg, loss: 4.8608, fps: 3.78 (0.26s per batch)\n",
      "\trpn_cls: 0.5977, rpn_box: 0.2250, rcnn_cls: 0.8988, rcnn_box: 0.0914, rcnn_pose: 0.2004\n",
      "step 147, image: 004625.jpg, loss: 10.6502, fps: 3.78 (0.26s per batch)\n",
      "\trpn_cls: 0.5784, rpn_box: 0.7318, rcnn_cls: 0.8655, rcnn_box: 0.0128, rcnn_pose: 1.7605\n",
      "step 148, image: 002478.jpg, loss: 9.6942, fps: 3.77 (0.26s per batch)\n",
      "\trpn_cls: 0.5536, rpn_box: 0.3598, rcnn_cls: 1.3811, rcnn_box: 0.0834, rcnn_pose: 3.3284\n",
      "step 149, image: 003144.jpg, loss: 2.6478, fps: 3.74 (0.27s per batch)\n",
      "\trpn_cls: 0.5559, rpn_box: 0.0383, rcnn_cls: 0.8373, rcnn_box: 0.0322, rcnn_pose: 0.5492\n",
      "step 150, image: 005352.jpg, loss: 5.2345, fps: 3.77 (0.27s per batch)\n",
      "\trpn_cls: 0.6023, rpn_box: 0.2851, rcnn_cls: 0.8611, rcnn_box: 0.0849, rcnn_pose: 0.0718\n",
      "step 151, image: 004386.jpg, loss: 3.6820, fps: 3.75 (0.27s per batch)\n",
      "\trpn_cls: 0.5734, rpn_box: 0.1232, rcnn_cls: 0.8303, rcnn_box: 0.0866, rcnn_pose: 0.1803\n",
      "step 152, image: 001115.jpg, loss: 7.7795, fps: 3.78 (0.26s per batch)\n",
      "\trpn_cls: 0.5280, rpn_box: 0.1112, rcnn_cls: 0.8514, rcnn_box: 0.0586, rcnn_pose: 4.7027\n",
      "step 153, image: 004294.jpg, loss: 6.3918, fps: 3.66 (0.27s per batch)\n",
      "\trpn_cls: 0.5894, rpn_box: 0.3827, rcnn_cls: 0.8463, rcnn_box: 0.1052, rcnn_pose: 0.0771\n",
      "step 154, image: 002634.jpg, loss: 9.5657, fps: 3.64 (0.27s per batch)\n",
      "\trpn_cls: 0.5511, rpn_box: 0.4403, rcnn_cls: 1.4394, rcnn_box: 0.0724, rcnn_pose: 2.4478\n",
      "step 155, image: 000108.jpg, loss: 4.3083, fps: 3.62 (0.28s per batch)\n",
      "\trpn_cls: 0.5495, rpn_box: 0.1676, rcnn_cls: 0.8057, rcnn_box: 0.0645, rcnn_pose: 0.6322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 156, image: 005287.jpg, loss: 5.8286, fps: 3.63 (0.28s per batch)\n",
      "\trpn_cls: 0.6121, rpn_box: 0.3384, rcnn_cls: 0.9336, rcnn_box: 0.0808, rcnn_pose: 0.0916\n",
      "step 157, image: 004927.jpg, loss: 12.2721, fps: 3.61 (0.28s per batch)\n",
      "\trpn_cls: 0.6006, rpn_box: 0.9030, rcnn_cls: 0.8323, rcnn_box: 0.0112, rcnn_pose: 1.6976\n",
      "step 158, image: 005619.jpg, loss: 12.0576, fps: 3.62 (0.28s per batch)\n",
      "\trpn_cls: 0.6147, rpn_box: 0.9281, rcnn_cls: 0.9780, rcnn_box: 0.0205, rcnn_pose: 0.9787\n",
      "step 159, image: 005734.jpg, loss: 5.8849, fps: 3.61 (0.28s per batch)\n",
      "\trpn_cls: 0.5750, rpn_box: 0.3474, rcnn_cls: 0.8310, rcnn_box: 0.0184, rcnn_pose: 0.8210\n",
      "step 160, image: 002426.jpg, loss: 8.4472, fps: 3.64 (0.27s per batch)\n",
      "\trpn_cls: 0.4686, rpn_box: 0.1665, rcnn_cls: 0.7298, rcnn_box: 0.1006, rcnn_pose: 4.5780\n",
      "step 161, image: 000965.jpg, loss: 14.3934, fps: 3.53 (0.28s per batch)\n",
      "\trpn_cls: 0.5825, rpn_box: 0.9247, rcnn_cls: 1.6147, rcnn_box: 0.2799, rcnn_pose: 0.1509\n",
      "step 162, image: 001940.jpg, loss: 10.1968, fps: 3.61 (0.28s per batch)\n",
      "\trpn_cls: 0.5177, rpn_box: 0.5451, rcnn_cls: 0.8766, rcnn_box: 0.2286, rcnn_pose: 1.0649\n",
      "step 163, image: 004188.jpg, loss: 15.6150, fps: 3.57 (0.28s per batch)\n",
      "\trpn_cls: 0.5077, rpn_box: 1.1263, rcnn_cls: 1.2145, rcnn_box: 0.2506, rcnn_pose: 0.1241\n",
      "step 164, image: 002234.jpg, loss: 3.2952, fps: 3.21 (0.31s per batch)\n",
      "\trpn_cls: 0.5672, rpn_box: 0.0910, rcnn_cls: 0.8143, rcnn_box: 0.0887, rcnn_pose: 0.1167\n",
      "step 165, image: 002033.jpg, loss: 12.8770, fps: 2.82 (0.35s per batch)\n",
      "\trpn_cls: 0.5952, rpn_box: 0.9975, rcnn_cls: 0.8676, rcnn_box: 0.0595, rcnn_pose: 0.8441\n",
      "step 166, image: 004515.jpg, loss: 5.8156, fps: 2.80 (0.36s per batch)\n",
      "\trpn_cls: 0.5749, rpn_box: 0.2794, rcnn_cls: 1.0329, rcnn_box: 0.1149, rcnn_pose: 0.2648\n",
      "step 167, image: 000593.jpg, loss: 6.2416, fps: 2.10 (0.48s per batch)\n",
      "\trpn_cls: 0.5329, rpn_box: 0.1970, rcnn_cls: 0.7372, rcnn_box: 0.0415, rcnn_pose: 2.5867\n",
      "step 168, image: 004416.jpg, loss: 7.9554, fps: 2.19 (0.46s per batch)\n",
      "\trpn_cls: 0.5281, rpn_box: 0.3959, rcnn_cls: 0.7916, rcnn_box: 0.0366, rcnn_pose: 2.3110\n",
      "step 169, image: 003943.jpg, loss: 5.7049, fps: 2.11 (0.47s per batch)\n",
      "\trpn_cls: 0.5151, rpn_box: 0.2174, rcnn_cls: 0.8355, rcnn_box: 0.1472, rcnn_pose: 0.7078\n",
      "step 170, image: 000032.jpg, loss: 5.7422, fps: 2.26 (0.44s per batch)\n",
      "\trpn_cls: 0.5629, rpn_box: 0.3412, rcnn_cls: 0.8469, rcnn_box: 0.0835, rcnn_pose: 0.0854\n",
      "step 171, image: 002148.jpg, loss: 10.5988, fps: 2.37 (0.42s per batch)\n",
      "\trpn_cls: 0.4934, rpn_box: 0.3975, rcnn_cls: 0.9235, rcnn_box: 0.2250, rcnn_pose: 2.9567\n",
      "step 172, image: 002239.jpg, loss: 4.3989, fps: 2.31 (0.43s per batch)\n",
      "\trpn_cls: 0.5242, rpn_box: 0.1393, rcnn_cls: 0.8740, rcnn_box: 0.0432, rcnn_pose: 1.1759\n",
      "step 173, image: 004076.jpg, loss: 7.6084, fps: 2.42 (0.41s per batch)\n",
      "\trpn_cls: 0.4832, rpn_box: 0.2618, rcnn_cls: 0.8147, rcnn_box: 0.0727, rcnn_pose: 2.9660\n",
      "step 174, image: 003287.jpg, loss: 4.1269, fps: 2.39 (0.42s per batch)\n",
      "\trpn_cls: 0.5396, rpn_box: 0.0858, rcnn_cls: 1.2874, rcnn_box: 0.1220, rcnn_pose: 0.2218\n",
      "step 175, image: 001582.jpg, loss: 6.6984, fps: 2.45 (0.41s per batch)\n",
      "\trpn_cls: 0.4933, rpn_box: 0.2951, rcnn_cls: 0.8593, rcnn_box: 0.1385, rcnn_pose: 1.0093\n",
      "step 176, image: 005156.jpg, loss: 6.3799, fps: 2.32 (0.43s per batch)\n",
      "\trpn_cls: 0.5345, rpn_box: 0.3407, rcnn_cls: 0.8410, rcnn_box: 0.1517, rcnn_pose: 0.0809\n",
      "step 177, image: 004443.jpg, loss: 8.0220, fps: 2.39 (0.42s per batch)\n",
      "\trpn_cls: 0.5489, rpn_box: 0.4772, rcnn_cls: 1.4312, rcnn_box: 0.0965, rcnn_pose: 0.3049\n",
      "step 178, image: 000582.jpg, loss: 4.5607, fps: 2.37 (0.42s per batch)\n",
      "\trpn_cls: 0.5184, rpn_box: 0.1767, rcnn_cls: 0.7905, rcnn_box: 0.1199, rcnn_pose: 0.2860\n",
      "step 179, image: 000633.jpg, loss: 4.9997, fps: 2.37 (0.42s per batch)\n",
      "\trpn_cls: 0.5276, rpn_box: 0.0472, rcnn_cls: 1.2970, rcnn_box: 0.0960, rcnn_pose: 1.7424\n",
      "step 180, image: 001516.jpg, loss: 9.5674, fps: 2.40 (0.42s per batch)\n",
      "\trpn_cls: 0.5548, rpn_box: 0.7165, rcnn_cls: 0.9242, rcnn_box: 0.0695, rcnn_pose: 0.2281\n",
      "step 181, image: 005263.jpg, loss: 6.8761, fps: 2.40 (0.42s per batch)\n",
      "\trpn_cls: 0.5658, rpn_box: 0.4352, rcnn_cls: 0.9986, rcnn_box: 0.0795, rcnn_pose: 0.1645\n",
      "step 182, image: 001870.jpg, loss: 7.3062, fps: 2.39 (0.42s per batch)\n",
      "\trpn_cls: 0.5580, rpn_box: 0.4074, rcnn_cls: 1.3318, rcnn_box: 0.0495, rcnn_pose: 0.8478\n",
      "step 183, image: 000311.jpg, loss: 7.2887, fps: 2.39 (0.42s per batch)\n",
      "\trpn_cls: 0.5771, rpn_box: 0.4901, rcnn_cls: 0.8682, rcnn_box: 0.0873, rcnn_pose: 0.0698\n",
      "step 184, image: 005022.jpg, loss: 4.2546, fps: 2.39 (0.42s per batch)\n",
      "\trpn_cls: 0.5439, rpn_box: 0.1898, rcnn_cls: 0.7956, rcnn_box: 0.0715, rcnn_pose: 0.3018\n",
      "step 185, image: 003504.jpg, loss: 3.7065, fps: 2.31 (0.43s per batch)\n",
      "\trpn_cls: 0.4949, rpn_box: 0.0334, rcnn_cls: 0.7712, rcnn_box: 0.0859, rcnn_pose: 1.2480\n",
      "step 186, image: 004961.jpg, loss: 4.7634, fps: 2.33 (0.43s per batch)\n",
      "\trpn_cls: 0.5714, rpn_box: 0.2119, rcnn_cls: 0.8594, rcnn_box: 0.0448, rcnn_pose: 0.7653\n",
      "step 187, image: 005918.jpg, loss: 10.8364, fps: 2.39 (0.42s per batch)\n",
      "\trpn_cls: 0.5346, rpn_box: 0.8352, rcnn_cls: 0.8779, rcnn_box: 0.0810, rcnn_pose: 0.2622\n",
      "step 188, image: 000282.jpg, loss: 6.4923, fps: 2.39 (0.42s per batch)\n",
      "\trpn_cls: 0.4982, rpn_box: 0.3366, rcnn_cls: 0.8060, rcnn_box: 0.1426, rcnn_pose: 0.3960\n",
      "step 189, image: 003440.jpg, loss: 5.9246, fps: 2.38 (0.42s per batch)\n",
      "\trpn_cls: 0.5972, rpn_box: 0.3153, rcnn_cls: 0.7959, rcnn_box: 0.1311, rcnn_pose: 0.0671\n",
      "step 190, image: 005025.jpg, loss: 3.8728, fps: 2.37 (0.42s per batch)\n",
      "\trpn_cls: 0.4900, rpn_box: 0.1678, rcnn_cls: 0.7521, rcnn_box: 0.0763, rcnn_pose: 0.1897\n",
      "step 191, image: 000027.jpg, loss: 20.0064, fps: 2.34 (0.43s per batch)\n",
      "\trpn_cls: 0.4435, rpn_box: 1.0811, rcnn_cls: 0.7279, rcnn_box: 0.0429, rcnn_pose: 7.5946\n",
      "step 192, image: 001014.jpg, loss: 4.1611, fps: 2.33 (0.43s per batch)\n",
      "\trpn_cls: 0.4706, rpn_box: 0.1064, rcnn_cls: 0.7532, rcnn_box: 0.1188, rcnn_pose: 0.6859\n",
      "step 193, image: 000995.jpg, loss: 4.3327, fps: 2.40 (0.42s per batch)\n",
      "\trpn_cls: 0.5259, rpn_box: 0.2112, rcnn_cls: 0.8089, rcnn_box: 0.0723, rcnn_pose: 0.1634\n",
      "step 194, image: 001158.jpg, loss: 7.3504, fps: 2.38 (0.42s per batch)\n",
      "\trpn_cls: 0.5321, rpn_box: 0.5057, rcnn_cls: 0.8969, rcnn_box: 0.0115, rcnn_pose: 0.7494\n",
      "step 195, image: 001904.jpg, loss: 5.6551, fps: 2.35 (0.43s per batch)\n",
      "\trpn_cls: 0.5468, rpn_box: 0.3532, rcnn_cls: 0.9190, rcnn_box: 0.0307, rcnn_pose: 0.3511\n",
      "step 196, image: 001918.jpg, loss: 5.1651, fps: 2.40 (0.42s per batch)\n",
      "\trpn_cls: 0.5235, rpn_box: 0.2884, rcnn_cls: 1.2482, rcnn_box: 0.0181, rcnn_pose: 0.3281\n",
      "step 197, image: 005435.jpg, loss: 9.2621, fps: 2.39 (0.42s per batch)\n",
      "\trpn_cls: 0.5161, rpn_box: 0.4942, rcnn_cls: 0.7744, rcnn_box: 0.0157, rcnn_pose: 2.8726\n",
      "step 198, image: 000733.jpg, loss: 4.4100, fps: 2.41 (0.42s per batch)\n",
      "\trpn_cls: 0.5087, rpn_box: 0.2423, rcnn_cls: 0.7335, rcnn_box: 0.0512, rcnn_pose: 0.2326\n",
      "step 199, image: 000237.jpg, loss: 5.0468, fps: 2.28 (0.44s per batch)\n",
      "\trpn_cls: 0.4178, rpn_box: 0.1597, rcnn_cls: 0.7168, rcnn_box: 0.1234, rcnn_pose: 1.0814\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "\n",
    "file_rpn_ce = open(output_dir+'/loss_rpn_ce.txt', 'w')\n",
    "file_rpn_box = open(output_dir+'/loss_rpn_box.txt', 'w')\n",
    "file_rcnn_ce = open(output_dir+'/loss_rcnn_ce.txt', 'w')\n",
    "file_rcnn_box = open(output_dir+'/loss_rcnn_box.txt', 'w')\n",
    "\n",
    "train_loss = 0.\n",
    "tp, tf, fg, bg = 0., 0., 0., 0.\n",
    "step_cnt = 0.\n",
    "re_cnt = False\n",
    "t = Timer()\n",
    "t.tic()\n",
    "#for step in range(start_step, end_step+1):\n",
    "for step in range(200):\n",
    "\n",
    "    # get one batch\n",
    "    blobs = data_layer.forward()\n",
    "    im_data = blobs['data'] # one image, shape = (1, H, W, 3)\n",
    "    im_info = blobs['im_info'] # stores H, W, scale\n",
    "    gt_boxes = blobs['gt_boxes'] # groundtruth boxes\n",
    "    gt_poses = blobs['gt_poses']\n",
    "    gt_ishard = blobs['gt_ishard']\n",
    "    dontcare_areas = blobs['dontcare_areas']\n",
    "    dontcare_poses = blobs['dontcare_poses']\n",
    "    disp_data = blobs['data_disp'] # disparity map\n",
    "\n",
    "    # forward\n",
    "    net(im_data, im_info, disp_data, gt_boxes, gt_poses, gt_ishard, dontcare_areas, dontcare_poses)\n",
    "    loss = net.loss + net.rpn.loss\n",
    "\n",
    "    if _DEBUG:\n",
    "        tp += float(net.tp)\n",
    "        tf += float(net.tf)\n",
    "        fg += net.fg_cnt\n",
    "        bg += net.bg_cnt\n",
    "\n",
    "    train_loss += loss.data[0]\n",
    "    step_cnt += 1\n",
    "\n",
    "    # backward\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    network.clip_gradient(net, 10.)\n",
    "    optimizer.step()\n",
    "    \n",
    "    # log losses to file\n",
    "    file_rpn_ce.write(str(net.rpn.cross_entropy.data.cpu().numpy()))\n",
    "    file_rpn_ce.write('\\n')\n",
    "    file_rpn_box.write(str(net.rpn.loss_box.data.cpu().numpy()))\n",
    "    file_rpn_box.write('\\n')\n",
    "    file_rcnn_ce.write(str(net.cross_entropy.data.cpu().numpy()))\n",
    "    file_rcnn_ce.write('\\n')\n",
    "    file_rcnn_box.write(str(net.loss_box.data.cpu().numpy()))\n",
    "    file_rcnn_box.write('\\n')\n",
    "\n",
    "    #if step % disp_interval == 0:\n",
    "    if step % 1 == 0:\n",
    "        duration = t.toc(average=False)\n",
    "        fps = step_cnt / duration\n",
    "\n",
    "        log_text = 'step %d, image: %s, loss: %.4f, fps: %.2f (%.2fs per batch)' % (\n",
    "            step, blobs['im_name'], train_loss / step_cnt, fps, 1./fps)\n",
    "        log_print(log_text, color='green', attrs=['bold'])\n",
    "\n",
    "        if _DEBUG:\n",
    "            #log_print('\\tTP: %.2f%%, TF: %.2f%%, fg/bg=(%d/%d)' % (tp/float(fg*100.), tf/float(bg*100.), fg/float(step_cnt), bg/float(step_cnt)))\n",
    "            log_print('\\trpn_cls: %.4f, rpn_box: %.4f, rcnn_cls: %.4f, rcnn_box: %.4f, rcnn_pose: %.4f' % (\n",
    "                net.rpn.cross_entropy.data.cpu().numpy(), net.rpn.loss_box.data.cpu().numpy(),\n",
    "                net.cross_entropy.data.cpu().numpy(), net.loss_box.data.cpu().numpy(), net.loss_pose.data.cpu().numpy())\n",
    "            )\n",
    "        re_cnt = True\n",
    "\n",
    "    if use_tensorboard and step % log_interval == 0:\n",
    "        exp.add_scalar_value('train_loss', train_loss / step_cnt, step=step)\n",
    "        exp.add_scalar_value('learning_rate', lr, step=step)\n",
    "        if _DEBUG:\n",
    "            exp.add_scalar_value('true_positive', tp/float(fg*100.), step=step)\n",
    "            exp.add_scalar_value('true_negative', tf/float(bg*100.), step=step)\n",
    "            losses = {'rpn_cls': float(net.rpn.cross_entropy.data.cpu().numpy()),\n",
    "                      'rpn_box': float(net.rpn.loss_box.data.cpu().numpy()),\n",
    "                      'rcnn_cls': float(net.cross_entropy.data.cpu().numpy()),\n",
    "                      'rcnn_box': float(net.loss_box.data.cpu().numpy()),\n",
    "                      'rcnn_pose': float(net.loss_pose.data.cpu().numpy())}\n",
    "            exp.add_scalar_dict(losses, step=step)\n",
    "\n",
    "    if (step % 10000 == 0) and step > 0:\n",
    "        save_name = os.path.join(output_dir, 'faster_rcnn_{}.h5'.format(step))\n",
    "        network.save_net(save_name, net)\n",
    "        print('save model: {}'.format(save_name))\n",
    "    if step in lr_decay_steps:\n",
    "        lr *= lr_decay\n",
    "        optimizer = torch.optim.SGD(params[8:], lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "\n",
    "    if re_cnt:\n",
    "        tp, tf, fg, bg = 0., 0., 0, 0\n",
    "        train_loss = 0\n",
    "        step_cnt = 0\n",
    "        t.tic()\n",
    "        re_cnt = False\n",
    "        \n",
    "file_rpn_ce.close()\n",
    "file_rpn_box.close()\n",
    "file_rcnn_ce.close()\n",
    "file_rcnn_box.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<class 'torch.autograd.variable.Variable'>, torch.Size([1]))\n",
      "(<class 'torch.autograd.variable.Variable'>, torch.Size([1]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([300, 5]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.cuda.IntTensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([300, 1000]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([300, 1000]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([300, 360]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([300, 60]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([300, 4096]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([300, 4096]))\n",
      "(<class 'torch.autograd.variable.Variable'>, torch.Size([1]))\n",
      "(<class 'torch.autograd.variable.Variable'>, torch.Size([1]))\n",
      "(<class 'torch.autograd.variable.Variable'>, torch.Size([1]))\n",
      "(<class 'torch.autograd.variable.Variable'>, torch.Size([1]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([1]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([1]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([1]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([1]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([1]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([1]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([512, 640, 3, 3]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([512]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([18, 512, 1, 1]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([18]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([36, 512, 1, 1]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([36]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([4096, 31360]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([4096]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([4096, 4096]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([4096]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([128]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([128, 128, 3, 3]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([128]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([128, 128, 3, 3]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([128]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([128, 128, 3, 3]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([4, 4096]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([4]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([16, 4096]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([16]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([1000, 31360]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([1000]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([1000, 1000]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([1000]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([360, 1000]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([360]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([60, 1000]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([60]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([6, 360]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([6]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([1, 60]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([1]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([64, 3, 3, 3]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([64]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([64, 64, 3, 3]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([64]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([128, 64, 3, 3]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([128]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([128, 128, 3, 3]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([128]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([256, 128, 3, 3]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([256]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([256, 256, 3, 3]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([256]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([256, 256, 3, 3]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([256]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([512, 256, 3, 3]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([512]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([512, 512, 3, 3]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([512]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([512, 512, 3, 3]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([512]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([512, 512, 3, 3]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([512]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([512, 512, 3, 3]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([512]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([512, 512, 3, 3]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([512]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([16, 1, 3, 3]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([16]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([16, 16, 3, 3]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([16]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([32, 16, 3, 3]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([32]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([32, 32, 3, 3]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([32]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([64, 32, 3, 3]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([64]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([64, 64, 3, 3]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([64]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([64, 64, 3, 3]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([64]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([128, 64, 3, 3]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([128]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([128, 128, 3, 3]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([128]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([128, 128, 3, 3]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([128]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([128, 128, 3, 3]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([128]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([128, 128, 3, 3]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([128]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([128, 128, 3, 3]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([128]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([512, 640, 3, 3]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([512]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([18, 512, 1, 1]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([18]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([36, 512, 1, 1]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([36]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([4096, 31360]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([4096]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([4096, 4096]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([4096]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([4, 4096]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([4]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([16, 4096]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([16]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([1000, 31360]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([1000]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([1000, 1000]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([1000]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([360, 1000]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([360]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([60, 1000]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([60]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([6, 360]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([6]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([1, 60]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([1]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([256, 128, 3, 3]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([256]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([256, 256, 3, 3]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([256]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([256, 256, 3, 3]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([256]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([512, 256, 3, 3]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([512]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([512, 512, 3, 3]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([512]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([512, 512, 3, 3]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([512]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([512, 512, 3, 3]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([512]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([512, 512, 3, 3]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([512]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([512, 512, 3, 3]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([512]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([16, 1, 3, 3]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([16]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([16, 16, 3, 3]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([16]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([32, 16, 3, 3]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([32]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([32, 32, 3, 3]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([32]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([64, 32, 3, 3]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([64]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([64, 64, 3, 3]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([64]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([64, 64, 3, 3]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([64]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([128, 64, 3, 3]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([128]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([128, 128, 3, 3]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([128]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([128, 128, 3, 3]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([128]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([128, 128, 3, 3]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([128]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([128, 128, 3, 3]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([128]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([128, 128, 3, 3]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([128]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([512, 640, 3, 3]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([512]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([18, 512, 1, 1]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([18]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([36, 512, 1, 1]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([36]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([4096, 31360]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([4096]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([4096, 4096]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([4096]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([4, 4096]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([4]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([16, 4096]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([16]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([1000, 31360]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([1000]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([1000, 1000]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([1000]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([360, 1000]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([360]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([60, 1000]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([60]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([6, 360]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([6]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([1, 60]))\n",
      "(<class 'torch.cuda.FloatTensor'>, torch.Size([1]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([64]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([64, 64, 3, 3]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([64]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([64, 3, 3, 3]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([256]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([256, 256, 3, 3]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([256]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([256, 128, 3, 3]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([256]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([256, 256, 3, 3]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([512]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([512, 512, 3, 3]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([512]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([512, 512, 3, 3]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([512]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([512, 512, 3, 3]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([16]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([16, 16, 3, 3]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([16]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([16, 1, 3, 3]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([128]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([128, 128, 3, 3]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([128]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([128, 64, 3, 3]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([512]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([512, 512, 3, 3]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([512]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([512, 256, 3, 3]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([512]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([512, 512, 3, 3]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([32]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([32, 32, 3, 3]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([32]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([32, 16, 3, 3]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([64]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([64, 64, 3, 3]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([64]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([64, 32, 3, 3]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([64]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([64, 64, 3, 3]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([128]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([128, 128, 3, 3]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([128]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([128, 128, 3, 3]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([128]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([128, 64, 3, 3]))\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "for obj in gc.get_objects():\n",
    "    if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):\n",
    "        print(type(obj), obj.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "temp",
   "language": "python",
   "name": "temp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
