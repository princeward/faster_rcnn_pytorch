{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "from faster_rcnn import network\n",
    "from faster_rcnn.faster_rcnn import FasterRCNN, RPN\n",
    "from faster_rcnn.utils.timer import Timer\n",
    "\n",
    "import faster_rcnn.roi_data_layer.roidb as rdl_roidb\n",
    "from faster_rcnn.roi_data_layer.layer import RoIDataLayer\n",
    "from faster_rcnn.datasets.factory import get_imdb\n",
    "from faster_rcnn.fast_rcnn.config import cfg, cfg_from_file\n",
    "\n",
    "try:\n",
    "    from termcolor import cprint\n",
    "except ImportError:\n",
    "    cprint = None\n",
    "\n",
    "try:\n",
    "    from pycrayon import CrayonClient\n",
    "except ImportError:\n",
    "    CrayonClient = None\n",
    "\n",
    "\n",
    "def log_print(text, color=None, on_color=None, attrs=None):\n",
    "    if cprint is not None:\n",
    "        cprint(text, color=color, on_color=on_color, attrs=attrs)\n",
    "    else:\n",
    "        print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyper-parameters\n",
    "# ------------\n",
    "#imdb_name = 'voc_2007_trainval'\n",
    "imdb_name = 'kittipose_train'\n",
    "cfg_file = 'experiments/cfgs/faster_rcnn_end2end.yml'\n",
    "pretrained_model = '/home/pculbert/Documents/faster_rcnn_pytorch/VGG_imagenet.npy'\n",
    "output_dir = 'trained_models/saved_pose_model0'\n",
    "\n",
    "start_step = 0\n",
    "end_step = 100000\n",
    "lr_decay_steps = {60000, 80000}\n",
    "lr_decay = 1./10\n",
    "\n",
    "rand_seed = 1024\n",
    "_DEBUG = True\n",
    "use_tensorboard = False\n",
    "remove_all_log = False   # remove all historical experiments in TensorBoard\n",
    "exp_name = None # the previous experiment name in TensorBoard\n",
    "\n",
    "# ------------\n",
    "\n",
    "if rand_seed is not None:\n",
    "    np.random.seed(rand_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load config\n",
    "cfg_from_file(cfg_file)\n",
    "lr = cfg.TRAIN.LEARNING_RATE\n",
    "momentum = cfg.TRAIN.MOMENTUM\n",
    "weight_decay = cfg.TRAIN.WEIGHT_DECAY\n",
    "disp_interval = cfg.TRAIN.DISPLAY\n",
    "log_interval = cfg.TRAIN.LOG_IMAGE_ITERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method kittipose.default_roidb of <faster_rcnn.datasets.kittipose.kittipose object at 0x7f907d3a5110>>\n",
      "Remove empty annotations:  005066 004339 004040 003383 001752 001091 000547 Done. \n",
      "kittipose_train gt roidb loaded from /home/pculbert/Documents/faster_rcnn_pytorch/data/cache/kittipose_train_gt_roidb.pkl\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "imdb = get_imdb(imdb_name)\n",
    "rdl_roidb.prepare_roidb(imdb)\n",
    "roidb = imdb.roidb\n",
    "# roidb is a database, containing bounding box info for all training images\n",
    "data_layer = RoIDataLayer(roidb, imdb.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load net\n",
    "net = FasterRCNN(classes=imdb.classes, debug=_DEBUG)\n",
    "network.weights_normal_init(net, dev=0.01)\n",
    "network.load_pretrained_npy(net, pretrained_model)\n",
    "# model_file = '/media/longc/Data/models/VGGnet_fast_rcnn_iter_70000.h5'\n",
    "# model_file = 'models/saved_model3/faster_rcnn_60000.h5'\n",
    "# network.load_net(model_file, net)\n",
    "# exp_name = 'vgg16_02-19_13-24'\n",
    "# start_step = 60001\n",
    "lr /= 10.\n",
    "# network.weights_normal_init([net.bbox_fc, net.score_fc, net.fc6, net.fc7], dev=0.01)\n",
    "\n",
    "net.cuda()\n",
    "net.train()\n",
    "\n",
    "params = list(net.parameters())\n",
    "# optimizer = torch.optim.Adam(params[-8:], lr=lr)\n",
    "optimizer = torch.optim.SGD(params[8:], lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# tensorboad\n",
    "use_tensorboard = use_tensorboard and CrayonClient is not None\n",
    "if use_tensorboard:\n",
    "    cc = CrayonClient(hostname='127.0.0.1')\n",
    "    if remove_all_log:\n",
    "        cc.remove_all_experiments()\n",
    "    if exp_name is None:\n",
    "        exp_name = datetime.now().strftime('vgg16_%m-%d_%H-%M')\n",
    "        exp = cc.create_experiment(exp_name)\n",
    "    else:\n",
    "        exp = cc.open_experiment(exp_name)\n",
    "        \n",
    "#for param in net.parameters():\n",
    "#    print(type(param.data), param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "faster_rcnn/faster_rcnn.py:76: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  rpn_cls_prob = F.softmax(rpn_cls_score_reshape)\n",
      "faster_rcnn/faster_rcnn.py:261: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  cls_prob = F.softmax(cls_score)\n",
      "/home/pculbert/.virtualenvs/temp/lib/python2.7/site-packages/ipykernel_launcher.py:38: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, image: 000356.jpg, loss: 220.8041, fps: 2.90 (0.34s per batch)\n",
      "\trpn_cls: 0.5921, rpn_box: 1.7224, rcnn_cls: 6.7181, rcnn_box: 19.6240, rcnn_pose: 0.0298\n",
      "step 1, image: 002457.jpg, loss: 103.4450, fps: 3.99 (0.25s per batch)\n",
      "\trpn_cls: 0.7366, rpn_box: 1.9560, rcnn_cls: 4.5297, rcnn_box: 7.8044, rcnn_pose: 0.5746\n",
      "step 2, image: 002830.jpg, loss: 180.7328, fps: 4.07 (0.25s per batch)\n",
      "\trpn_cls: 0.6828, rpn_box: 0.7027, rcnn_cls: 9.0641, rcnn_box: 16.3518, rcnn_pose: 0.4411\n",
      "step 3, image: 003728.jpg, loss: 94.6832, fps: 3.93 (0.25s per batch)\n",
      "\trpn_cls: 0.6547, rpn_box: 3.1288, rcnn_cls: 5.1460, rcnn_box: 5.7563, rcnn_pose: 0.0311\n",
      "step 4, image: 004072.jpg, loss: 92.3013, fps: 3.92 (0.26s per batch)\n",
      "\trpn_cls: 0.6693, rpn_box: 1.8611, rcnn_cls: 4.9854, rcnn_box: 6.7288, rcnn_pose: 0.7476\n",
      "step 5, image: 002123.jpg, loss: 200.9737, fps: 3.99 (0.25s per batch)\n",
      "\trpn_cls: 0.6730, rpn_box: 1.5226, rcnn_cls: 6.7180, rcnn_box: 17.8212, rcnn_pose: 0.1455\n",
      "step 6, image: 001734.jpg, loss: 170.9590, fps: 4.04 (0.25s per batch)\n",
      "\trpn_cls: 0.6422, rpn_box: 1.9671, rcnn_cls: 6.0261, rcnn_box: 14.4589, rcnn_pose: 0.0311\n",
      "step 7, image: 002192.jpg, loss: 65.3963, fps: 3.91 (0.26s per batch)\n",
      "\trpn_cls: 0.6794, rpn_box: 1.9162, rcnn_cls: 5.4202, rcnn_box: 3.9513, rcnn_pose: 0.6217\n",
      "step 8, image: 001417.jpg, loss: 151.9718, fps: 3.92 (0.26s per batch)\n",
      "\trpn_cls: 0.6699, rpn_box: 1.2339, rcnn_cls: 5.8444, rcnn_box: 13.3097, rcnn_pose: 0.0207\n",
      "step 9, image: 002596.jpg, loss: 63.8728, fps: 3.96 (0.25s per batch)\n",
      "\trpn_cls: 0.6937, rpn_box: 2.5341, rcnn_cls: 2.6427, rcnn_box: 3.4701, rcnn_pose: 0.4943\n",
      "step 10, image: 004570.jpg, loss: 104.7487, fps: 3.93 (0.25s per batch)\n",
      "\trpn_cls: 0.6867, rpn_box: 3.3129, rcnn_cls: 2.3017, rcnn_box: 6.8298, rcnn_pose: 0.3333\n",
      "step 11, image: 002170.jpg, loss: 92.1314, fps: 3.91 (0.26s per batch)\n",
      "\trpn_cls: 0.6978, rpn_box: 2.6329, rcnn_cls: 3.4028, rcnn_box: 6.1433, rcnn_pose: 0.2680\n",
      "step 12, image: 004343.jpg, loss: 7963.4688, fps: 3.97 (0.25s per batch)\n",
      "\trpn_cls: 0.6852, rpn_box: 2.4129, rcnn_cls: 0.0000, rcnn_box: 0.0000, rcnn_pose: 7938.6548\n",
      "step 13, image: 005341.jpg, loss: 36.9527, fps: 3.89 (0.26s per batch)\n",
      "\trpn_cls: 0.7235, rpn_box: 0.7413, rcnn_cls: 2.5208, rcnn_box: 2.6017, rcnn_pose: 0.2777\n",
      "step 14, image: 001039.jpg, loss: 129.8302, fps: 3.98 (0.25s per batch)\n",
      "\trpn_cls: 0.6527, rpn_box: 2.2090, rcnn_cls: 5.3353, rcnn_box: 10.1685, rcnn_pose: 0.0669\n",
      "step 15, image: 000493.jpg, loss: 92.0376, fps: 3.95 (0.25s per batch)\n",
      "\trpn_cls: 0.6299, rpn_box: 1.9756, rcnn_cls: 3.5099, rcnn_box: 6.8115, rcnn_pose: 0.0266\n",
      "step 16, image: 003753.jpg, loss: 69.7593, fps: 3.84 (0.26s per batch)\n",
      "\trpn_cls: 0.6052, rpn_box: 1.8185, rcnn_cls: 3.9952, rcnn_box: 4.6950, rcnn_pose: 0.0242\n",
      "step 17, image: 004763.jpg, loss: 133.0520, fps: 3.99 (0.25s per batch)\n",
      "\trpn_cls: 0.6728, rpn_box: 1.7013, rcnn_cls: 3.0523, rcnn_box: 11.2038, rcnn_pose: 0.2759\n",
      "step 18, image: 003458.jpg, loss: 87.5452, fps: 3.99 (0.25s per batch)\n",
      "\trpn_cls: 0.6298, rpn_box: 1.8835, rcnn_cls: 6.3434, rcnn_box: 6.1551, rcnn_pose: 0.1861\n",
      "step 19, image: 004467.jpg, loss: 127.9202, fps: 3.88 (0.26s per batch)\n",
      "\trpn_cls: 0.6357, rpn_box: 1.9513, rcnn_cls: 4.4622, rcnn_box: 10.3267, rcnn_pose: 0.0420\n",
      "step 20, image: 000295.jpg, loss: 110.7394, fps: 3.86 (0.26s per batch)\n",
      "\trpn_cls: 0.6310, rpn_box: 3.3169, rcnn_cls: 3.4501, rcnn_box: 7.3411, rcnn_pose: 0.0785\n",
      "step 21, image: 002145.jpg, loss: 140.5253, fps: 3.90 (0.26s per batch)\n",
      "\trpn_cls: 0.6136, rpn_box: 1.5408, rcnn_cls: 5.5909, rcnn_box: 11.8892, rcnn_pose: 0.0214\n",
      "step 22, image: 005464.jpg, loss: 42.9322, fps: 4.05 (0.25s per batch)\n",
      "\trpn_cls: 0.6856, rpn_box: 1.6221, rcnn_cls: 2.8714, rcnn_box: 2.2856, rcnn_pose: 0.2980\n",
      "step 23, image: 005731.jpg, loss: 94.8801, fps: 4.03 (0.25s per batch)\n",
      "\trpn_cls: 0.6601, rpn_box: 0.3824, rcnn_cls: 3.5756, rcnn_box: 8.6705, rcnn_pose: 0.1163\n",
      "step 24, image: 000584.jpg, loss: 71.0455, fps: 3.87 (0.26s per batch)\n",
      "\trpn_cls: 0.6563, rpn_box: 1.3134, rcnn_cls: 2.5871, rcnn_box: 5.4207, rcnn_pose: 0.4609\n",
      "step 25, image: 000982.jpg, loss: 64.2585, fps: 3.93 (0.25s per batch)\n",
      "\trpn_cls: 0.6161, rpn_box: 1.7578, rcnn_cls: 3.0855, rcnn_box: 4.2925, rcnn_pose: 0.0547\n",
      "step 26, image: 002324.jpg, loss: 99.0891, fps: 3.90 (0.26s per batch)\n",
      "\trpn_cls: 0.6466, rpn_box: 0.4563, rcnn_cls: 3.5793, rcnn_box: 9.0216, rcnn_pose: 0.0839\n",
      "step 27, image: 005024.jpg, loss: 85.4337, fps: 3.83 (0.26s per batch)\n",
      "\trpn_cls: 0.6880, rpn_box: 1.0142, rcnn_cls: 3.1578, rcnn_box: 7.1418, rcnn_pose: 0.0281\n",
      "step 28, image: 004422.jpg, loss: 41.5841, fps: 3.89 (0.26s per batch)\n",
      "\trpn_cls: 0.6857, rpn_box: 0.9656, rcnn_cls: 2.8071, rcnn_box: 2.8289, rcnn_pose: 0.1459\n",
      "step 29, image: 004782.jpg, loss: 96.7490, fps: 4.02 (0.25s per batch)\n",
      "\trpn_cls: 0.7055, rpn_box: 0.8474, rcnn_cls: 3.0672, rcnn_box: 8.4476, rcnn_pose: 0.0264\n",
      "step 30, image: 002550.jpg, loss: 102.1519, fps: 3.94 (0.25s per batch)\n",
      "\trpn_cls: 0.6994, rpn_box: 0.1212, rcnn_cls: 4.4009, rcnn_box: 9.5819, rcnn_pose: 0.0203\n",
      "step 31, image: 000327.jpg, loss: 47.9798, fps: 3.90 (0.26s per batch)\n",
      "\trpn_cls: 0.6569, rpn_box: 0.6250, rcnn_cls: 3.3001, rcnn_box: 3.7690, rcnn_pose: 0.0825\n",
      "step 32, image: 001278.jpg, loss: 38.0018, fps: 3.90 (0.26s per batch)\n",
      "\trpn_cls: 0.6571, rpn_box: 1.4741, rcnn_cls: 2.2273, rcnn_box: 2.0237, rcnn_pose: 0.1389\n",
      "step 33, image: 004277.jpg, loss: 43.0492, fps: 3.96 (0.25s per batch)\n",
      "\trpn_cls: 0.6953, rpn_box: 1.9881, rcnn_cls: 2.2576, rcnn_box: 1.9991, rcnn_pose: 0.2242\n",
      "step 34, image: 001812.jpg, loss: 58.0018, fps: 3.83 (0.26s per batch)\n",
      "\trpn_cls: 0.6604, rpn_box: 1.4968, rcnn_cls: 2.9356, rcnn_box: 3.9415, rcnn_pose: 0.0232\n",
      "step 35, image: 005242.jpg, loss: 25.4738, fps: 3.92 (0.25s per batch)\n",
      "\trpn_cls: 0.6784, rpn_box: 0.5960, rcnn_cls: 2.0421, rcnn_box: 1.6623, rcnn_pose: 0.1697\n",
      "step 36, image: 005331.jpg, loss: 111.3700, fps: 3.90 (0.26s per batch)\n",
      "\trpn_cls: 0.6800, rpn_box: 1.6179, rcnn_cls: 2.9354, rcnn_box: 9.0962, rcnn_pose: 0.6132\n",
      "step 37, image: 001624.jpg, loss: 65.8895, fps: 3.96 (0.25s per batch)\n",
      "\trpn_cls: 0.6614, rpn_box: 0.9957, rcnn_cls: 2.3993, rcnn_box: 5.2846, rcnn_pose: 0.0264\n",
      "step 38, image: 005583.jpg, loss: 54.7351, fps: 3.99 (0.25s per batch)\n",
      "\trpn_cls: 0.6734, rpn_box: 1.2928, rcnn_cls: 2.5432, rcnn_box: 3.8539, rcnn_pose: 0.0515\n",
      "step 39, image: 000928.jpg, loss: 65.1934, fps: 3.88 (0.26s per batch)\n",
      "\trpn_cls: 0.6784, rpn_box: 0.9026, rcnn_cls: 2.7865, rcnn_box: 5.2695, rcnn_pose: 0.0077\n",
      "step 40, image: 000887.jpg, loss: 29.2235, fps: 4.00 (0.25s per batch)\n",
      "\trpn_cls: 0.6836, rpn_box: 1.7532, rcnn_cls: 2.3216, rcnn_box: 0.8482, rcnn_pose: 0.2045\n",
      "step 41, image: 001159.jpg, loss: 24.6354, fps: 3.97 (0.25s per batch)\n",
      "\trpn_cls: 0.6757, rpn_box: 1.2422, rcnn_cls: 2.4045, rcnn_box: 0.8961, rcnn_pose: 0.1714\n",
      "step 42, image: 000320.jpg, loss: 55.8732, fps: 3.97 (0.25s per batch)\n",
      "\trpn_cls: 0.6589, rpn_box: 1.6161, rcnn_cls: 2.4765, rcnn_box: 3.6543, rcnn_pose: 0.0334\n",
      "step 43, image: 003483.jpg, loss: 77.3575, fps: 3.93 (0.25s per batch)\n",
      "\trpn_cls: 0.6851, rpn_box: 1.2924, rcnn_cls: 3.1985, rcnn_box: 6.0530, rcnn_pose: 0.0196\n",
      "step 44, image: 005285.jpg, loss: 55.6074, fps: 3.82 (0.26s per batch)\n",
      "\trpn_cls: 0.6995, rpn_box: 1.7435, rcnn_cls: 2.2739, rcnn_box: 3.5154, rcnn_pose: 0.0447\n",
      "step 45, image: 005521.jpg, loss: 43.1226, fps: 3.93 (0.25s per batch)\n",
      "\trpn_cls: 0.6711, rpn_box: 1.1602, rcnn_cls: 1.9953, rcnn_box: 2.8417, rcnn_pose: 0.4373\n",
      "step 46, image: 005326.jpg, loss: 66.5122, fps: 4.01 (0.25s per batch)\n",
      "\trpn_cls: 0.6757, rpn_box: 0.9853, rcnn_cls: 2.8284, rcnn_box: 5.3120, rcnn_pose: 0.0350\n",
      "step 47, image: 003215.jpg, loss: 28.2143, fps: 3.93 (0.25s per batch)\n",
      "\trpn_cls: 0.6798, rpn_box: 1.1597, rcnn_cls: 1.9475, rcnn_box: 1.3900, rcnn_pose: 0.0901\n",
      "step 48, image: 005533.jpg, loss: 22.1084, fps: 3.82 (0.26s per batch)\n",
      "\trpn_cls: 0.6889, rpn_box: 1.1972, rcnn_cls: 1.6328, rcnn_box: 0.7633, rcnn_pose: 0.1814\n",
      "step 49, image: 004387.jpg, loss: 19.9734, fps: 3.87 (0.26s per batch)\n",
      "\trpn_cls: 0.6865, rpn_box: 1.1846, rcnn_cls: 1.7164, rcnn_box: 0.5569, rcnn_pose: 0.1558\n",
      "step 50, image: 005654.jpg, loss: 31.6292, fps: 3.89 (0.26s per batch)\n",
      "\trpn_cls: 0.6633, rpn_box: 1.2358, rcnn_cls: 2.1345, rcnn_box: 1.6422, rcnn_pose: 0.0514\n",
      "step 51, image: 004470.jpg, loss: 25.6085, fps: 3.85 (0.26s per batch)\n",
      "\trpn_cls: 0.6816, rpn_box: 0.1909, rcnn_cls: 1.8889, rcnn_box: 2.0966, rcnn_pose: 0.1626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 52, image: 003758.jpg, loss: 28.8271, fps: 3.92 (0.26s per batch)\n",
      "\trpn_cls: 0.6877, rpn_box: 0.8251, rcnn_cls: 2.1541, rcnn_box: 1.7715, rcnn_pose: 0.0194\n",
      "step 53, image: 001709.jpg, loss: 41.8120, fps: 3.96 (0.25s per batch)\n",
      "\trpn_cls: 0.6829, rpn_box: 0.8029, rcnn_cls: 2.3695, rcnn_box: 3.0713, rcnn_pose: 0.0178\n",
      "step 54, image: 000749.jpg, loss: 30.5596, fps: 4.01 (0.25s per batch)\n",
      "\trpn_cls: 0.6823, rpn_box: 1.3290, rcnn_cls: 2.7096, rcnn_box: 1.3738, rcnn_pose: 0.1392\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (2) : out of memory at /pytorch/aten/src/THC/generic/THCStorage.cu:58",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-bc24a910cbb0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;31m# backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pculbert/.virtualenvs/temp/local/lib/python2.7/site-packages/torch/tensor.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m \u001b[0;34m`\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pculbert/.virtualenvs/temp/local/lib/python2.7/site-packages/torch/autograd/__init__.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     87\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     88\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (2) : out of memory at /pytorch/aten/src/THC/generic/THCStorage.cu:58"
     ]
    }
   ],
   "source": [
    "# training\n",
    "\n",
    "file_rpn_ce = open(output_dir+'/loss_rpn_ce.txt', 'w')\n",
    "file_rpn_box = open(output_dir+'/loss_rpn_box.txt', 'w')\n",
    "file_rcnn_ce = open(output_dir+'/loss_rcnn_ce.txt', 'w')\n",
    "file_rcnn_box = open(output_dir+'/loss_rcnn_box.txt', 'w')\n",
    "\n",
    "train_loss = 0.\n",
    "tp, tf, fg, bg = 0., 0., 0., 0.\n",
    "step_cnt = 0.\n",
    "re_cnt = False\n",
    "t = Timer()\n",
    "t.tic()\n",
    "#for step in range(start_step, end_step+1):\n",
    "for step in range(200):\n",
    "\n",
    "    # get one batch\n",
    "    blobs = data_layer.forward()\n",
    "    im_data = blobs['data'] # one image, shape = (1, H, W, 3)\n",
    "    im_info = blobs['im_info'] # stores H, W, scale\n",
    "    gt_boxes = blobs['gt_boxes'] # groundtruth boxes\n",
    "    gt_poses = blobs['gt_poses']\n",
    "    gt_ishard = blobs['gt_ishard']\n",
    "    dontcare_areas = blobs['dontcare_areas']\n",
    "    dontcare_poses = blobs['dontcare_poses']\n",
    "    disp_data = blobs['data_disp'] # disparity map\n",
    "\n",
    "    # forward\n",
    "    net(im_data, im_info, disp_data, gt_boxes, gt_poses, gt_ishard, dontcare_areas, dontcare_poses)\n",
    "    loss = net.loss + net.rpn.loss\n",
    "\n",
    "    if _DEBUG:\n",
    "        tp += float(net.tp)\n",
    "        tf += float(net.tf)\n",
    "        fg += net.fg_cnt\n",
    "        bg += net.bg_cnt\n",
    "\n",
    "    train_loss += loss.data[0]\n",
    "    step_cnt += 1\n",
    "\n",
    "    # backward\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    network.clip_gradient(net, 10.)\n",
    "    optimizer.step()\n",
    "    \n",
    "    # log losses to file\n",
    "    file_rpn_ce.write(str(net.rpn.cross_entropy.data.cpu().numpy()))\n",
    "    file_rpn_ce.write('\\n')\n",
    "    file_rpn_box.write(str(net.rpn.loss_box.data.cpu().numpy()))\n",
    "    file_rpn_box.write('\\n')\n",
    "    file_rcnn_ce.write(str(net.cross_entropy.data.cpu().numpy()))\n",
    "    file_rcnn_ce.write('\\n')\n",
    "    file_rcnn_box.write(str(net.loss_box.data.cpu().numpy()))\n",
    "    file_rcnn_box.write('\\n')\n",
    "\n",
    "    #if step % disp_interval == 0:\n",
    "    if step % 1 == 0:\n",
    "        duration = t.toc(average=False)\n",
    "        fps = step_cnt / duration\n",
    "\n",
    "        log_text = 'step %d, image: %s, loss: %.4f, fps: %.2f (%.2fs per batch)' % (\n",
    "            step, blobs['im_name'], train_loss / step_cnt, fps, 1./fps)\n",
    "        log_print(log_text, color='green', attrs=['bold'])\n",
    "\n",
    "        if _DEBUG:\n",
    "            #log_print('\\tTP: %.2f%%, TF: %.2f%%, fg/bg=(%d/%d)' % (tp/float(fg*100.), tf/float(bg*100.), fg/float(step_cnt), bg/float(step_cnt)))\n",
    "            log_print('\\trpn_cls: %.4f, rpn_box: %.4f, rcnn_cls: %.4f, rcnn_box: %.4f, rcnn_pose: %.4f' % (\n",
    "                net.rpn.cross_entropy.data.cpu().numpy(), net.rpn.loss_box.data.cpu().numpy(),\n",
    "                net.cross_entropy.data.cpu().numpy(), net.loss_box.data.cpu().numpy(), net.loss_pose.data.cpu().numpy())\n",
    "            )\n",
    "        re_cnt = True\n",
    "\n",
    "    if use_tensorboard and step % log_interval == 0:\n",
    "        exp.add_scalar_value('train_loss', train_loss / step_cnt, step=step)\n",
    "        exp.add_scalar_value('learning_rate', lr, step=step)\n",
    "        if _DEBUG:\n",
    "            exp.add_scalar_value('true_positive', tp/float(fg*100.), step=step)\n",
    "            exp.add_scalar_value('true_negative', tf/float(bg*100.), step=step)\n",
    "            losses = {'rpn_cls': float(net.rpn.cross_entropy.data.cpu().numpy()),\n",
    "                      'rpn_box': float(net.rpn.loss_box.data.cpu().numpy()),\n",
    "                      'rcnn_cls': float(net.cross_entropy.data.cpu().numpy()),\n",
    "                      'rcnn_box': float(net.loss_box.data.cpu().numpy()),\n",
    "                      'rcnn_pose': float(net.loss_pose.data.cpu().numpy())}\n",
    "            exp.add_scalar_dict(losses, step=step)\n",
    "\n",
    "    if (step % 10000 == 0) and step > 0:\n",
    "        save_name = os.path.join(output_dir, 'faster_rcnn_{}.h5'.format(step))\n",
    "        network.save_net(save_name, net)\n",
    "        print('save model: {}'.format(save_name))\n",
    "    if step in lr_decay_steps:\n",
    "        lr *= lr_decay\n",
    "        optimizer = torch.optim.SGD(params[8:], lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "\n",
    "    if re_cnt:\n",
    "        tp, tf, fg, bg = 0., 0., 0, 0\n",
    "        train_loss = 0\n",
    "        step_cnt = 0\n",
    "        t.tic()\n",
    "        re_cnt = False\n",
    "        \n",
    "file_rpn_ce.close()\n",
    "file_rpn_box.close()\n",
    "file_rcnn_ce.close()\n",
    "file_rcnn_box.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([128, 128, 3, 3]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([128]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([512, 640, 3, 3]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([512]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([18, 512, 1, 1]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([18]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([36, 512, 1, 1]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([36]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([4096, 31360]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([4096]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([4096, 4096]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([4096]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([4, 4096]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([4]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([16, 4096]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([16]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([7, 4096]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([7]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([128]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([128, 128, 3, 3]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([128]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([128, 128, 3, 3]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 5]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([256, 128, 3, 3]))\n",
      "(<class 'torch.Tensor'>, torch.Size([256]))\n",
      "(<class 'torch.Tensor'>, torch.Size([256, 256, 3, 3]))\n",
      "(<class 'torch.Tensor'>, torch.Size([256]))\n",
      "(<class 'torch.Tensor'>, torch.Size([256, 256, 3, 3]))\n",
      "(<class 'torch.Tensor'>, torch.Size([256]))\n",
      "(<class 'torch.Tensor'>, torch.Size([512, 256, 3, 3]))\n",
      "(<class 'torch.Tensor'>, torch.Size([512]))\n",
      "(<class 'torch.Tensor'>, torch.Size([512, 512, 3, 3]))\n",
      "(<class 'torch.Tensor'>, torch.Size([512]))\n",
      "(<class 'torch.Tensor'>, torch.Size([512, 512, 3, 3]))\n",
      "(<class 'torch.Tensor'>, torch.Size([512]))\n",
      "(<class 'torch.Tensor'>, torch.Size([512, 512, 3, 3]))\n",
      "(<class 'torch.Tensor'>, torch.Size([512]))\n",
      "(<class 'torch.Tensor'>, torch.Size([512, 512, 3, 3]))\n",
      "(<class 'torch.Tensor'>, torch.Size([512]))\n",
      "(<class 'torch.Tensor'>, torch.Size([512, 512, 3, 3]))\n",
      "(<class 'torch.Tensor'>, torch.Size([512]))\n",
      "(<class 'torch.Tensor'>, torch.Size([16, 1, 3, 3]))\n",
      "(<class 'torch.Tensor'>, torch.Size([16]))\n",
      "(<class 'torch.Tensor'>, torch.Size([16, 16, 3, 3]))\n",
      "(<class 'torch.Tensor'>, torch.Size([16]))\n",
      "(<class 'torch.Tensor'>, torch.Size([32, 16, 3, 3]))\n",
      "(<class 'torch.Tensor'>, torch.Size([32]))\n",
      "(<class 'torch.Tensor'>, torch.Size([32, 32, 3, 3]))\n",
      "(<class 'torch.Tensor'>, torch.Size([32]))\n",
      "(<class 'torch.Tensor'>, torch.Size([64, 32, 3, 3]))\n",
      "(<class 'torch.Tensor'>, torch.Size([64]))\n",
      "(<class 'torch.Tensor'>, torch.Size([64, 64, 3, 3]))\n",
      "(<class 'torch.Tensor'>, torch.Size([64]))\n",
      "(<class 'torch.Tensor'>, torch.Size([64, 64, 3, 3]))\n",
      "(<class 'torch.Tensor'>, torch.Size([64]))\n",
      "(<class 'torch.Tensor'>, torch.Size([128, 64, 3, 3]))\n",
      "(<class 'torch.Tensor'>, torch.Size([128]))\n",
      "(<class 'torch.Tensor'>, torch.Size([128, 128, 3, 3]))\n",
      "(<class 'torch.Tensor'>, torch.Size([128]))\n",
      "(<class 'torch.Tensor'>, torch.Size([128, 128, 3, 3]))\n",
      "(<class 'torch.Tensor'>, torch.Size([128]))\n",
      "(<class 'torch.Tensor'>, torch.Size([128, 128, 3, 3]))\n",
      "(<class 'torch.Tensor'>, torch.Size([128]))\n",
      "(<class 'torch.Tensor'>, torch.Size([128, 128, 3, 3]))\n",
      "(<class 'torch.Tensor'>, torch.Size([128]))\n",
      "(<class 'torch.Tensor'>, torch.Size([128, 128, 3, 3]))\n",
      "(<class 'torch.Tensor'>, torch.Size([128]))\n",
      "(<class 'torch.Tensor'>, torch.Size([512, 640, 3, 3]))\n",
      "(<class 'torch.Tensor'>, torch.Size([512]))\n",
      "(<class 'torch.Tensor'>, torch.Size([18, 512, 1, 1]))\n",
      "(<class 'torch.Tensor'>, torch.Size([18]))\n",
      "(<class 'torch.Tensor'>, torch.Size([36, 512, 1, 1]))\n",
      "(<class 'torch.Tensor'>, torch.Size([36]))\n",
      "(<class 'torch.Tensor'>, torch.Size([4096, 31360]))\n",
      "(<class 'torch.Tensor'>, torch.Size([4096]))\n",
      "(<class 'torch.Tensor'>, torch.Size([4096, 4096]))\n",
      "(<class 'torch.Tensor'>, torch.Size([4096]))\n",
      "(<class 'torch.Tensor'>, torch.Size([4, 4096]))\n",
      "(<class 'torch.Tensor'>, torch.Size([4]))\n",
      "(<class 'torch.Tensor'>, torch.Size([16, 4096]))\n",
      "(<class 'torch.Tensor'>, torch.Size([16]))\n",
      "(<class 'torch.Tensor'>, torch.Size([7, 4096]))\n",
      "(<class 'torch.Tensor'>, torch.Size([7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 5]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 5]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 5]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 5]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 5]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 5]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 5]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 5]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 5]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 5]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 5]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 5]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 5]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 5]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 5]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 5]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 5]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 5]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 5]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 5]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 5]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 5]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 5]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 5]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([]))\n",
      "(<class 'torch.Tensor'>, torch.Size([]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 4096]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 4096]))\n",
      "(<class 'torch.Tensor'>, torch.Size([]))\n",
      "(<class 'torch.Tensor'>, torch.Size([]))\n",
      "(<class 'torch.Tensor'>, torch.Size([]))\n",
      "(<class 'torch.Tensor'>, torch.Size([]))\n",
      "(<class 'torch.Tensor'>, torch.Size([]))\n",
      "(<class 'torch.Tensor'>, torch.Size([]))\n",
      "(<class 'torch.Tensor'>, torch.Size([]))\n",
      "(<class 'torch.Tensor'>, torch.Size([]))\n",
      "(<class 'torch.Tensor'>, torch.Size([]))\n",
      "(<class 'torch.Tensor'>, torch.Size([]))\n",
      "(<class 'torch.Tensor'>, torch.Size([]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 5]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 5]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 5]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 5]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 5]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 5]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 5]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 5]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 5]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 5]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 5]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 5]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 5]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 5]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 5]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 5]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 5]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 5]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 5]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 5]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 5]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 5]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 5]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 5]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 5]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 5]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 5]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 5]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 5]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 5]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 5]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([300, 640, 7, 7]))\n",
      "(<class 'torch.Tensor'>, torch.Size([]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([64]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([64, 64, 3, 3]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([64]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([64, 3, 3, 3]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([256]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([256, 256, 3, 3]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([256]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([256, 128, 3, 3]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([256]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([256, 256, 3, 3]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([512]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([512, 512, 3, 3]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([512]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([512, 256, 3, 3]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([512]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([512, 512, 3, 3]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([128]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([128, 128, 3, 3]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([128]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([128, 64, 3, 3]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([512]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([512, 512, 3, 3]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([512]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([512, 512, 3, 3]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([512]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([512, 512, 3, 3]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([16]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([16, 16, 3, 3]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([16]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([16, 1, 3, 3]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([32]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([32, 32, 3, 3]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([32]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([32, 16, 3, 3]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([64]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([64, 64, 3, 3]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([64]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([64, 32, 3, 3]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([64]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([64, 64, 3, 3]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([128]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([128, 128, 3, 3]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([128]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([128, 64, 3, 3]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([128]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([128, 128, 3, 3]))\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "for obj in gc.get_objects():\n",
    "    if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):\n",
    "        print(type(obj), obj.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "temp",
   "language": "python",
   "name": "temp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
