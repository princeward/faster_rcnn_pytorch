{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import cv2\n",
    "import cPickle\n",
    "import numpy as np\n",
    "\n",
    "from faster_rcnn import network\n",
    "from faster_rcnn.faster_rcnn import FasterRCNN, RPN\n",
    "from faster_rcnn.utils.timer import Timer\n",
    "from faster_rcnn.fast_rcnn.nms_wrapper import nms\n",
    "\n",
    "from faster_rcnn.fast_rcnn.bbox_transform import bbox_transform_inv, clip_boxes\n",
    "from faster_rcnn.datasets.factory import get_imdb\n",
    "from faster_rcnn.fast_rcnn.config import cfg, cfg_from_file, get_output_dir\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi']= 300\n",
    "\n",
    "\n",
    "# hyper-parameters\n",
    "# ------------\n",
    "#imdb_name = 'voc_2007_test'\n",
    "#imdb_name = 'kittivoc_train'\n",
    "imdb_name = 'kittivoc_val'\n",
    "#imdb_name = 'kitti_train'\n",
    "cfg_file = 'experiments/cfgs/faster_rcnn_end2end.yml'\n",
    "trained_model = 'models/saved_model6/faster_rcnn_20000.h5'\n",
    "\n",
    "# rand_seed = 1024\n",
    "\n",
    "save_name = 'faster_rcnn_100000'\n",
    "max_per_image = 300\n",
    "thresh = 0.05\n",
    "vis = True\n",
    "\n",
    "# ------------\n",
    "\n",
    "# load config\n",
    "cfg_from_file(cfg_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method kittivoc.default_roidb of <faster_rcnn.datasets.kittivoc.kittivoc object at 0x7f3cc56f8a90>>\n",
      "Remove empty annotations:  Done. \n",
      "load model successfully!\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "imdb = get_imdb(imdb_name)\n",
    "imdb.competition_mode(on=True)\n",
    "\n",
    "# load net\n",
    "net = FasterRCNN(classes=imdb.classes, debug=False)\n",
    "network.load_net(trained_model, net)\n",
    "print('load model successfully!')\n",
    "\n",
    "net.cuda()\n",
    "net.eval(); # set network to evaluation mode, which affects the behavior of batch norm, dropout, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_detections(im, class_name, dets, thresh=0.8):\n",
    "    \"\"\"Visual debugging of detections.\"\"\"\n",
    "    for i in range(np.minimum(10, dets.shape[0])):\n",
    "        bbox = tuple(int(np.round(x)) for x in dets[i, :4])\n",
    "        score = dets[i, -1]\n",
    "        if score > thresh:\n",
    "            cv2.rectangle(im, bbox[0:2], bbox[2:4], (0, 204, 0), 2)\n",
    "            cv2.putText(im, '%s: %.3f' % (class_name, score), (bbox[0], bbox[1] + 15), cv2.FONT_HERSHEY_PLAIN,\n",
    "                        1.0, (0, 0, 255), thickness=1)\n",
    "    return im\n",
    "\n",
    "\n",
    "def im_detect(net, image, disparity):\n",
    "    \"\"\"Detect object classes in an image given object proposals.\n",
    "    Returns:\n",
    "        scores (ndarray): R x K array of object class scores (K includes\n",
    "            background as object category 0)\n",
    "        boxes (ndarray): R x (4*K) array of predicted bounding boxes\n",
    "    \"\"\"\n",
    "    # image.shape = H x W x 3\n",
    "    # im_data, im_scales = net.get_image_blob(image)\n",
    "    im_data, im_scales, disp_data = net.get_image_disparity_blob(image, disparity)\n",
    "    # get_image_blob() tries to make H = 600 but keep W <= 1000\n",
    "    # image gets resized, and the resize scale is returned\n",
    "    # im_data: 1 x H x W x 3\n",
    "    # im_scales: array with one number\n",
    "\n",
    "    im_info = np.array(\n",
    "        [[im_data.shape[1], im_data.shape[2], im_scales[0]]],\n",
    "        dtype=np.float32)\n",
    "\n",
    "    cls_prob, bbox_pred, rois = net(im_data, im_info, disp_data)\n",
    "    # cls_prob.shape = (300, 4) # KITTI has four classes, '__background__', 'Car', 'Pedestrian', 'Cyclist'\n",
    "    # bbox_pred.shape = (300, 16)\n",
    "    # rois.shape = (300, 5)\n",
    "    \n",
    "    scores = cls_prob.data.cpu().numpy()\n",
    "    boxes = rois.data.cpu().numpy()[:, 1:5] / im_info[0][2]\n",
    "    cfg.TEST.BBOX_REG = True\n",
    "    if cfg.TEST.BBOX_REG: # True in this case\n",
    "        # Apply bounding-box regression deltas\n",
    "        box_deltas = bbox_pred.data.cpu().numpy()\n",
    "        pred_boxes = bbox_transform_inv(boxes, box_deltas)\n",
    "        pred_boxes = clip_boxes(pred_boxes, image.shape)\n",
    "        # pred_boxes.shape = (300, 16)\n",
    "    else:\n",
    "        # Simply repeat the boxes, once for each class\n",
    "        pred_boxes = np.tile(boxes, (1, scores.shape[1]))\n",
    "\n",
    "    return scores, pred_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_per_image=300\n",
    "thresh=0.05\n",
    "# idx_image = 6 # the idx of the image that we want to test\n",
    "num_images = len(imdb.image_index)\n",
    "idx_image = np.random.randint(0, num_images, 1)[0]\n",
    "\n",
    "\n",
    "# all detections are collected into:\n",
    "#    all_boxes[cls][image] = N x 5 array of detections in\n",
    "#    (x1, y1, x2, y2, score)\n",
    "all_boxes = [[[] for _ in xrange(num_images)]\n",
    "             for _ in xrange(imdb.num_classes)]\n",
    "\n",
    "\n",
    "# timers\n",
    "_t = {'im_detect': Timer(), 'misc': Timer()}\n",
    "\n",
    "print \"# of images: \", num_images\n",
    "\n",
    "# for i in range(num_images):\n",
    "for i in range(idx_image,idx_image+1):\n",
    "    im_path = imdb.image_path_at(i)\n",
    "    folder = im_path[0:-10]\n",
    "    img_name = im_path[-10:-3]\n",
    "    img_name += 'png'\n",
    "    disp_path = folder + 'disparity/' + img_name # path to disparity map\n",
    "    \n",
    "    im = cv2.imread(im_path)\n",
    "    disp = cv2.imread(disp_path)\n",
    "    \n",
    "    _t['im_detect'].tic()\n",
    "    \n",
    "    scores, boxes = im_detect(net, im, disp_path)\n",
    "    # scores.shape = (300, 4)\n",
    "    # boxes.shape = (300, 16)\n",
    "    \n",
    "    detect_time = _t['im_detect'].toc(average=False)\n",
    "\n",
    "    \n",
    "    if vis:\n",
    "        # im2show = np.copy(im[:, :, (2, 1, 0)])\n",
    "        im2show = np.copy(im)\n",
    "\n",
    "    # skip j = 0, because it's the background class\n",
    "    for j in xrange(1, imdb.num_classes):\n",
    "        inds = np.where(scores[:, j] > thresh)[0]\n",
    "        cls_scores = scores[inds, j]\n",
    "        cls_boxes = boxes[inds, j * 4:(j + 1) * 4]\n",
    "        cls_dets = np.hstack((cls_boxes, cls_scores[:, np.newaxis])) \\\n",
    "            .astype(np.float32, copy=False)\n",
    "        keep = nms(cls_dets, cfg.TEST.NMS)\n",
    "        cls_dets = cls_dets[keep, :]\n",
    "        if vis:\n",
    "            im2show = vis_detections(im2show, imdb.classes[j], cls_dets)\n",
    "        all_boxes[j][i] = cls_dets\n",
    "\n",
    "    # Limit to max_per_image detections *over all classes*\n",
    "    _t['misc'].tic()\n",
    "    if max_per_image > 0:\n",
    "        image_scores = np.hstack([all_boxes[j][i][:, -1]\n",
    "                                  for j in xrange(1, imdb.num_classes)])\n",
    "        if len(image_scores) > max_per_image:\n",
    "            image_thresh = np.sort(image_scores)[-max_per_image]\n",
    "            for j in xrange(1, imdb.num_classes):\n",
    "                keep = np.where(all_boxes[j][i][:, -1] >= image_thresh)[0]\n",
    "                all_boxes[j][i] = all_boxes[j][i][keep, :]\n",
    "    nms_time = _t['misc'].toc(average=False)\n",
    "\n",
    "    print 'im_detect: {:d}/{:d} {:.3f}s {:.3f}s' \\\n",
    "        .format(i + 1, num_images, detect_time, nms_time)\n",
    "\n",
    "    if vis:\n",
    "        #cv2.imshow('test', im2show)\n",
    "        #cv2.waitKey(0)\n",
    "        plt.imshow(im2show)\n",
    "        #pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "temp",
   "language": "python",
   "name": "temp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
